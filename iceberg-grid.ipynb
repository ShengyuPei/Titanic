{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% run utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorboardX import SummaryWriter\n",
    "import skimage.transform as transform\n",
    "import networkx as nx\n",
    "from scipy import spatial\n",
    "import pytorch_fft.fft as fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('train.json')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = StandardScaler()\n",
    "for r in df.band_1:\n",
    "    s.partial_fit(np.reshape(r, (-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = transform.rescale(np.reshape(df.band_1[100], (75, 75)), 0.5, mode='constant')\n",
    "plt.imshow(b);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid(m):\n",
    "    idx = np.arange(m)\n",
    "    return np.reshape(np.meshgrid(idx, idx), (2, -1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(z, k=4, metric='euclidean'):\n",
    "    d = spatial.distance.pdist(z, metric)\n",
    "    d = spatial.distance.squareform(d)\n",
    "    \n",
    "    width = d.mean() # preserve distribution\n",
    "    w = np.exp(- np.square(d / width))\n",
    "    np.fill_diagonal(w, 0)\n",
    "    \n",
    "    cut = w < np.sort(w, axis=1)[:, -k]\n",
    "    w[cut & np.transpose(cut)] = 0\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplacian(weights):\n",
    "    degrees = np.sum(weights, axis=1)\n",
    "    laplacian = np.diag(degrees) - weights\n",
    "    inv_D_sqrt = np.linalg.inv(np.diag(degrees)) ** (1/2)\n",
    "    laplacian = inv_D_sqrt @ laplacian @ inv_D_sqrt\n",
    "    return laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.spy(distance(grid(3), k=3, metric='cityblock'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd = spatial.distance.squareform(spatial.distance.pdist(b.reshape(-1, 1), metric='euclidean'))\n",
    "plt.matshow(rd);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba = b.copy()\n",
    "rd[np.where(distance(grid(38), k=2) == 0)] = 0\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(rd[:100, :100])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.spy(rd);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lap = laplacian(rd)\n",
    "\n",
    "plt.spy(lap[:100, :100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourier(laplacian):\n",
    "    return sp.linalg.svd(laplacian)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(fourier(lap));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_numpy_array(rd)\n",
    "\n",
    "nx.draw(nx.subgraph(G, list(G.nodes())[:38 * 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coarsening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = sp.sparse.csr.csr_matrix(distance(grid(3), 2, metric='cityblock'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.spy(G.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs, perm = coarsening.coarsen(G, levels=2, self_connections=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for g in graphs:\n",
    "    plt.subplot(121)\n",
    "    plt.spy(g.todense())\n",
    "    plt.subplot(122)\n",
    "    nx.draw(nx.from_numpy_array(g.todense()))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr = grid(38)\n",
    "gr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = distance(gr, k=3) > 0\n",
    "plt.spy(mask[:40, :40]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs, perm = coarsening.coarsen(sp.sparse.csr.csr_matrix(mask), levels=3, self_connections=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse.csgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laps = [sp.sparse.csgraph.laplacian(g, normed=True) for g in graphs[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = laps[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gf = df.copy()\n",
    "gf = gf.assign(\n",
    "    band_1=df.band_1\n",
    "        .apply(lambda x: transform.rescale(np.reshape(x, (75, 75)), 0.5, mode='constant'))\n",
    "        .apply(lambda x: np.r_[x[tuple(gr.reshape(2, -1))], np.zeros(n - 38 * 38)][perm])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorify(col):\n",
    "    data = s.transform(np.stack(col.values))\n",
    "    return torch.from_numpy(data.reshape(-1, n)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_train_test = np.random.rand(len(gf)) < 0.9\n",
    "train = gf[split_train_test]\n",
    "test = gf[~split_train_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = tensorify(train.band_1)\n",
    "test_x = tensorify(test.band_1)\n",
    "train_y = torch.from_numpy(train.is_iceberg.values.reshape(-1, 1)).float()\n",
    "test_y = torch.from_numpy(test.is_iceberg.values.reshape(-1, 1)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = False#torch.cuda.is_available()\n",
    "num_epochs = 1\n",
    "batch_size = 2\n",
    "learning_rate = 0.00005\n",
    "cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data_utils.DataLoader(data_utils.TensorDataset(train_x, train_y), batch_size=batch_size, shuffle=True)\n",
    "test_loader = data_utils.DataLoader(data_utils.TensorDataset(test_x, test_y), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = fourier(laps[0].todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = Variable(next(train_loader.__iter__())[0])\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.FloatTensor(5,3,4,1)\n",
    "y = torch.FloatTensor(  3,1,1)\n",
    "torch.matmul(x, y).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.from_numpy(np.array([[[1], [2]], [[3], [1]]])).float().transpose(0, 2)\n",
    "y = torch.from_numpy(np.array([[[1, 2, 3]], [[3, 2, 1]]])).float().transpose(0, 2)\n",
    "print(y)\n",
    "print(x)\n",
    "y @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConv(nn.Module):\n",
    "    def __init__(self, fourier, n_filter):\n",
    "        super(GraphConv, self).__init__()\n",
    "        \n",
    "        self.n = len(fourier)\n",
    "        self.u = Variable(torch.from_numpy(fourier).float(), requires_grad=False)        \n",
    "        self.n_filter = n_filter\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.Tensor(self.n, self.n_filter))\n",
    "        self.bias = nn.Parameter(torch.Tensor(self.n))\n",
    "        \n",
    "        stdv = 1. / np.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, x): # samples x n\n",
    "        # fourier\n",
    "        out = x @ self.u # samples x n\n",
    "        \n",
    "        # filtre\n",
    "        w = self.weight.unsqueeze(2) # n x f x 1\n",
    "        out = out.t().unsqueeze(1) # n x 1 x samples\n",
    "        out = w @ out # n x f x samples\n",
    "        \n",
    "        # un-fourier\n",
    "        out = out.permute(2, 1, 0).contiguous() # samples x f x n\n",
    "        out = out.view(-1, self.n) # (samples * f) x n\n",
    "        out = out @ self.u.t() # (samples * f) x n\n",
    "        out = out.view(-1, self.n_filter, self.n) # samples x f x n\n",
    "        \n",
    "        # bias?\n",
    "        out = out + self.bias # samples x f x n\n",
    "        return F.relu(out) # samples x f x n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GraphConv(f, 4)(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    GraphConv(f, 2),\n",
    "    Flatten(),\n",
    "    nn.Linear(n * 2, 200),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(200, 2),\n",
    "    nn.Softmax(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "writer = SummaryWriter()\n",
    "\n",
    "if cuda:\n",
    "    net.cuda()\n",
    "    criterion.cuda()\n",
    "    \n",
    "epoch_train_loss = []\n",
    "epoch_test_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(5):\n",
    "\n",
    "    train_loss = 0\n",
    "    test_loss = 0\n",
    "\n",
    "    for batch_id, (x, y) in enumerate(tqdm(train_loader, desc='Training')):\n",
    "        x = Variable(x)\n",
    "        y = Variable(y).long().squeeze()\n",
    "        \n",
    "        if cuda:\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net(x)\n",
    "        loss = criterion(outputs, y)\n",
    "        \n",
    "        train_loss += loss.data.cpu()[0]\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    writer.add_scalar('data/scalar1', train_loss, e)\n",
    "      \n",
    "    for batch_id, (x, y) in enumerate(tqdm(test_loader, desc='Testing')):\n",
    "        x = Variable(x)\n",
    "        y = Variable(y).long().squeeze()\n",
    "        \n",
    "        if cuda:\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "        outputs = net(x)\n",
    "        loss = criterion(outputs, y)\n",
    "\n",
    "        test_loss += loss.data.cpu()[0]\n",
    "     \n",
    "    train_loss /= train.shape[0]\n",
    "    test_loss /= test.shape[0]\n",
    "    \n",
    "    epoch_train_loss.append(train_loss)\n",
    "    epoch_test_loss.append(test_loss)\n",
    "    print('Training loss: {:.4f}'.format(train_loss))\n",
    "    print('Testing  loss: {:.4f}'.format(test_loss))\n",
    "    \n",
    "writer.add_graph(net, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch_train_loss, label='train')\n",
    "plt.plot(epoch_test_loss, label='test')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "targets = []\n",
    "\n",
    "for batch_id, (x, y) in enumerate(tqdm(train_loader, desc='Training')):\n",
    "    x = Variable(x)\n",
    "    y = Variable(y).long().squeeze()\n",
    "\n",
    "    if cuda:\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "    \n",
    "    outputs = net(x)\n",
    "    preds.extend(outputs.data.cpu().numpy().argmax(axis=1))\n",
    "    targets.extend(y.data.cpu().numpy())\n",
    "\n",
    "accuracy_score(targets, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss(targets, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "targets = []\n",
    "\n",
    "for batch_id, (x, y) in enumerate(tqdm(test_loader, desc='Testing')):\n",
    "    x = Variable(x)\n",
    "    y = Variable(y).long().squeeze()\n",
    "\n",
    "    if cuda:\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "    \n",
    "    outputs = net(x)\n",
    "    preds.extend(outputs.data.cpu().numpy().argmax(axis=1))\n",
    "    targets.extend(y.data.cpu().numpy())\n",
    "\n",
    "accuracy_score(targets, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss(targets, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
