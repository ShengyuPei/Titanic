{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "% run 1-datasource.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorify(data):\n",
    "    return torch.from_numpy(data.reshape(-1, 1, 75, 75)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band_1</th>\n",
       "      <th>band_2</th>\n",
       "      <th>inc_angle</th>\n",
       "      <th>is_iceberg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dfd5f913</th>\n",
       "      <td>[-27.878361, -27.15416, -28.668615, -29.537971...</td>\n",
       "      <td>[-27.154118, -29.537888, -31.0306, -32.190483,...</td>\n",
       "      <td>43.9239</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e25388fd</th>\n",
       "      <td>[-12.242375, -14.920305, -14.920363, -12.66633...</td>\n",
       "      <td>[-31.506321, -27.984554, -26.645678, -23.76760...</td>\n",
       "      <td>38.1562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58b2aaa0</th>\n",
       "      <td>[-24.603676, -24.603714, -24.871029, -23.15277...</td>\n",
       "      <td>[-24.870956, -24.092632, -20.653963, -19.41104...</td>\n",
       "      <td>45.2859</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4cfc3a18</th>\n",
       "      <td>[-22.454607, -23.082819, -23.998013, -23.99805...</td>\n",
       "      <td>[-27.889421, -27.519794, -27.165262, -29.10350...</td>\n",
       "      <td>43.8306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271f93f4</th>\n",
       "      <td>[-26.006956, -23.164886, -23.164886, -26.89116...</td>\n",
       "      <td>[-27.206915, -30.259186, -30.259186, -23.16495...</td>\n",
       "      <td>35.6256</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     band_1  \\\n",
       "id                                                            \n",
       "dfd5f913  [-27.878361, -27.15416, -28.668615, -29.537971...   \n",
       "e25388fd  [-12.242375, -14.920305, -14.920363, -12.66633...   \n",
       "58b2aaa0  [-24.603676, -24.603714, -24.871029, -23.15277...   \n",
       "4cfc3a18  [-22.454607, -23.082819, -23.998013, -23.99805...   \n",
       "271f93f4  [-26.006956, -23.164886, -23.164886, -26.89116...   \n",
       "\n",
       "                                                     band_2  inc_angle  \\\n",
       "id                                                                       \n",
       "dfd5f913  [-27.154118, -29.537888, -31.0306, -32.190483,...    43.9239   \n",
       "e25388fd  [-31.506321, -27.984554, -26.645678, -23.76760...    38.1562   \n",
       "58b2aaa0  [-24.870956, -24.092632, -20.653963, -19.41104...    45.2859   \n",
       "4cfc3a18  [-27.889421, -27.519794, -27.165262, -29.10350...    43.8306   \n",
       "271f93f4  [-27.206915, -30.259186, -30.259186, -23.16495...    35.6256   \n",
       "\n",
       "          is_iceberg  \n",
       "id                    \n",
       "dfd5f913           0  \n",
       "e25388fd           0  \n",
       "58b2aaa0           1  \n",
       "4cfc3a18           0  \n",
       "271f93f4           0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icebergs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(241, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(icebergs, test_size=0.15, stratify=icebergs.is_iceberg)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_1 = StandardScaler()\n",
    "scaler_2 = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, i in train.iterrows():\n",
    "    scaler_1.partial_fit(i.band_1.reshape(1, -1))\n",
    "    scaler_2.partial_fit(i.band_2.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.from_numpy(\n",
    "    np.stack(\n",
    "        [\n",
    "            scaler_1.transform(np.stack(train.band_1)),\n",
    "            scaler_2.transform(np.stack(train.band_2)),\n",
    "        ],\n",
    "        axis=1\n",
    "    ).reshape(-1, 2, 75, 75)\n",
    ").float()\n",
    "test_x = torch.from_numpy(\n",
    "    np.stack(\n",
    "        [\n",
    "            scaler_1.transform(np.stack(test.band_1)),\n",
    "            scaler_2.transform(np.stack(test.band_2)),\n",
    "        ],\n",
    "        axis=1\n",
    "    ).reshape(-1, 2, 75, 75)\n",
    ").float()\n",
    "train_y = torch.from_numpy(train.is_iceberg.values.reshape(-1, 1)).float()\n",
    "test_y = torch.from_numpy(test.is_iceberg.values.reshape(-1, 1)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1363, 2, 5625)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a =  np.stack(\n",
    "        [\n",
    "            scaler_1.transform(np.stack(train.band_1)),\n",
    "            scaler_2.transform(np.stack(train.band_2)),\n",
    "        ],\n",
    "        axis=1)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "num_epochs = 250\n",
    "batch_size = 32\n",
    "learning_rate = 0.000001\n",
    "cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data_utils.DataLoader(data_utils.TensorDataset(train_x, train_y), batch_size=batch_size, shuffle=True)\n",
    "test_loader = data_utils.DataLoader(data_utils.TensorDataset(test_x, test_y), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "insize1 = 2 \n",
    "outsize1 = 16\n",
    "outsize2 = 16\n",
    "outsize3 = 32\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(insize1, outsize1, kernel_size=7, stride=1, padding=2, groups=2),\n",
    "            nn.BatchNorm2d(outsize1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(4)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(outsize1, outsize2, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(outsize2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(outsize2*81, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "writer = SummaryWriter()\n",
    "writer.add_graph(net, net(Variable(train_x.narrow(0, 0, 1))))\n",
    "\n",
    "if cuda:\n",
    "    net.cuda()\n",
    "    criterion.cuda()\n",
    "    \n",
    "epoch_train_loss = []\n",
    "epoch_test_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop(loader, training=False):\n",
    "    \n",
    "    running_loss = 0\n",
    "    targets = []\n",
    "    predictions = []\n",
    "    \n",
    "    for batch_id, (x, y) in enumerate(loader):\n",
    "        x = Variable(x)\n",
    "        y = Variable(y)\n",
    "        \n",
    "        if cuda:\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net(x)\n",
    "        loss = criterion(outputs, y)\n",
    "\n",
    "        if training:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        running_loss += loss.data.cpu()[0]\n",
    "        targets.extend(y.data.cpu().numpy())\n",
    "        predictions.extend(outputs.sigmoid().data.cpu().numpy())\n",
    "        \n",
    "    return np.array(targets), np.array(predictions), running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______ > Training loss: 0.0217\n",
      "Testing  loss: 0.0228\n",
      "______ > Training loss: 0.0216\n",
      "Testing  loss: 0.0227\n",
      "______ > Training loss: 0.0215\n",
      "Testing  loss: 0.0226\n",
      "______ > Training loss: 0.0214\n",
      "Testing  loss: 0.0226\n",
      "______ > Training loss: 0.0213\n",
      "Testing  loss: 0.0226\n",
      "______ > Training loss: 0.0212\n",
      "Testing  loss: 0.0224\n",
      "______ > Training loss: 0.0212\n",
      "Testing  loss: 0.0224\n",
      "______ > Training loss: 0.0211\n",
      "Testing  loss: 0.0224\n",
      "______ > Training loss: 0.0210\n",
      "Testing  loss: 0.0223\n",
      "______ > Training loss: 0.0210\n",
      "Testing  loss: 0.0223\n",
      "______ > Training loss: 0.0209\n",
      "Testing  loss: 0.0224\n",
      "______ > Training loss: 0.0209\n",
      "Testing  loss: 0.0222\n",
      "______ > Training loss: 0.0208\n",
      "Testing  loss: 0.0222\n",
      "______ > Training loss: 0.0207\n",
      "Testing  loss: 0.0221\n",
      "______ > Training loss: 0.0207\n",
      "Testing  loss: 0.0223\n",
      "______ > Training loss: 0.0207\n",
      "Testing  loss: 0.0222\n",
      "______ > Training loss: 0.0206\n",
      "Testing  loss: 0.0221\n",
      "______ > Training loss: 0.0207\n",
      "Testing  loss: 0.0221\n",
      "______ > Training loss: 0.0206\n",
      "Testing  loss: 0.0221\n",
      "______ > Training loss: 0.0206\n",
      "Testing  loss: 0.0220\n",
      "______ > Training loss: 0.0205\n",
      "Testing  loss: 0.0220\n",
      "______ > Training loss: 0.0204\n",
      "Testing  loss: 0.0223\n",
      "______ > Training loss: 0.0204\n",
      "Testing  loss: 0.0222\n",
      "______ > Training loss: 0.0204\n",
      "Testing  loss: 0.0219\n",
      "______ > Training loss: 0.0204\n",
      "Testing  loss: 0.0221\n",
      "______ > Training loss: 0.0203\n",
      "Testing  loss: 0.0219\n",
      "______ > Training loss: 0.0204\n",
      "Testing  loss: 0.0218\n",
      "______ > Training loss: 0.0202\n",
      "Testing  loss: 0.0216\n",
      "______ > Training loss: 0.0202\n",
      "Testing  loss: 0.0218\n",
      "______ > Training loss: 0.0202\n",
      "Testing  loss: 0.0217\n",
      "______ > Training loss: 0.0202\n",
      "Testing  loss: 0.0216\n",
      "______ > Training loss: 0.0201\n",
      "Testing  loss: 0.0217\n",
      "______ > Training loss: 0.0201\n",
      "Testing  loss: 0.0218\n",
      "______ > Training loss: 0.0201\n",
      "Testing  loss: 0.0216\n",
      "______ > Training loss: 0.0200\n",
      "Testing  loss: 0.0215\n",
      "______ > Training loss: 0.0200\n",
      "Testing  loss: 0.0216\n",
      "______ > Training loss: 0.0200\n",
      "Testing  loss: 0.0216\n",
      "______ > Training loss: 0.0200\n",
      "Testing  loss: 0.0217\n",
      "______ > Training loss: 0.0200\n",
      "Testing  loss: 0.0215\n",
      "______ > Training loss: 0.0199\n",
      "Testing  loss: 0.0217\n",
      "______ > Training loss: 0.0199\n",
      "Testing  loss: 0.0215\n",
      "______ > Training loss: 0.0198\n",
      "Testing  loss: 0.0213\n",
      "______ > Training loss: 0.0198\n",
      "Testing  loss: 0.0212\n",
      "______ > Training loss: 0.0198\n",
      "Testing  loss: 0.0214\n",
      "______ > Training loss: 0.0198\n",
      "Testing  loss: 0.0214\n",
      "______ > Training loss: 0.0197\n",
      "Testing  loss: 0.0211\n",
      "______ > Training loss: 0.0197\n",
      "Testing  loss: 0.0213\n",
      "______ > Training loss: 0.0197\n",
      "Testing  loss: 0.0212\n",
      "______ > Training loss: 0.0197\n",
      "Testing  loss: 0.0215\n",
      "______ > Training loss: 0.0197\n",
      "Testing  loss: 0.0212\n",
      "______ > Training loss: 0.0196\n",
      "Testing  loss: 0.0209\n",
      "______ > Training loss: 0.0195\n",
      "Testing  loss: 0.0210\n",
      "______ > Training loss: 0.0194\n",
      "Testing  loss: 0.0208\n",
      "______ > Training loss: 0.0195\n",
      "Testing  loss: 0.0211\n",
      "______ > Training loss: 0.0194\n",
      "Testing  loss: 0.0209\n",
      "______ > Training loss: 0.0194\n",
      "Testing  loss: 0.0211\n",
      "______ > Training loss: 0.0194\n",
      "Testing  loss: 0.0210\n",
      "______ > Training loss: 0.0193\n",
      "Testing  loss: 0.0208\n",
      "______ > Training loss: 0.0194\n",
      "Testing  loss: 0.0208\n",
      "______ > Training loss: 0.0194\n",
      "Testing  loss: 0.0208\n",
      "______ > Training loss: 0.0194\n",
      "Testing  loss: 0.0208\n",
      "______ > Training loss: 0.0194\n",
      "Testing  loss: 0.0208\n",
      "______ > Training loss: 0.0193\n",
      "Testing  loss: 0.0208\n",
      "______ > Training loss: 0.0192\n",
      "Testing  loss: 0.0206\n",
      "______ > Training loss: 0.0192\n",
      "Testing  loss: 0.0206\n",
      "______ > Training loss: 0.0191\n",
      "Testing  loss: 0.0206\n",
      "______ > Training loss: 0.0191\n",
      "Testing  loss: 0.0206\n",
      "______ > Training loss: 0.0191\n",
      "Testing  loss: 0.0205\n",
      "______ > Training loss: 0.0191\n",
      "Testing  loss: 0.0207\n",
      "______ > Training loss: 0.0190\n",
      "Testing  loss: 0.0207\n",
      "______ > Training loss: 0.0190\n",
      "Testing  loss: 0.0205\n",
      "______ > Training loss: 0.0190\n",
      "Testing  loss: 0.0203\n",
      "______ > Training loss: 0.0189\n",
      "Testing  loss: 0.0206\n",
      "______ > Training loss: 0.0189\n",
      "Testing  loss: 0.0205\n",
      "______ > Training loss: 0.0188\n",
      "Testing  loss: 0.0203\n",
      "______ > Training loss: 0.0189\n",
      "Testing  loss: 0.0203\n",
      "______ > Training loss: 0.0188\n",
      "Testing  loss: 0.0202\n",
      "______ > Training loss: 0.0188\n",
      "Testing  loss: 0.0202\n",
      "______ > Training loss: 0.0187\n",
      "Testing  loss: 0.0203\n",
      "______ > Training loss: 0.0187\n",
      "Testing  loss: 0.0205\n",
      "______ > Training loss: 0.0187\n",
      "Testing  loss: 0.0203\n",
      "______ > Training loss: 0.0187\n",
      "Testing  loss: 0.0202\n",
      "______ > Training loss: 0.0187\n",
      "Testing  loss: 0.0200\n",
      "______ > Training loss: 0.0185\n",
      "Testing  loss: 0.0200\n",
      "______ > Training loss: 0.0185\n",
      "Testing  loss: 0.0199\n",
      "______ > Training loss: 0.0186\n",
      "Testing  loss: 0.0205\n",
      "______ > Training loss: 0.0185\n",
      "Testing  loss: 0.0201\n",
      "______ > Training loss: 0.0185\n",
      "Testing  loss: 0.0197\n",
      "______ > Training loss: 0.0185\n",
      "Testing  loss: 0.0201\n",
      "______ > Training loss: 0.0185\n",
      "Testing  loss: 0.0199\n",
      "______ > Training loss: 0.0185\n",
      "Testing  loss: 0.0199\n",
      "______ > Training loss: 0.0184\n",
      "Testing  loss: 0.0202\n",
      "______ > Training loss: 0.0184\n",
      "Testing  loss: 0.0201\n",
      "______ > Training loss: 0.0184\n",
      "Testing  loss: 0.0200\n",
      "______ > Training loss: 0.0183\n",
      "Testing  loss: 0.0196\n",
      "______ > Training loss: 0.0182\n",
      "Testing  loss: 0.0198\n",
      "______ > Training loss: 0.0182\n",
      "Testing  loss: 0.0197\n",
      "______ > Training loss: 0.0181\n",
      "Testing  loss: 0.0201\n",
      "______ > Training loss: 0.0181\n",
      "Testing  loss: 0.0202\n",
      "______ > Training loss: 0.0180\n",
      "Testing  loss: 0.0195\n",
      "______ > Training loss: 0.0182\n",
      "Testing  loss: 0.0199\n",
      "______ > Training loss: 0.0180\n",
      "Testing  loss: 0.0197\n",
      "______ > Training loss: 0.0181\n",
      "Testing  loss: 0.0194\n",
      "______ > Training loss: 0.0180\n",
      "Testing  loss: 0.0194\n",
      "______ > Training loss: 0.0181\n",
      "Testing  loss: 0.0195\n",
      "______ > Training loss: 0.0179\n",
      "Testing  loss: 0.0192\n",
      "______ > Training loss: 0.0179\n",
      "Testing  loss: 0.0193\n",
      "______ > Training loss: 0.0178\n",
      "Testing  loss: 0.0198\n",
      "______ > Training loss: 0.0178\n",
      "Testing  loss: 0.0190\n",
      "______ > Training loss: 0.0178\n",
      "Testing  loss: 0.0192\n",
      "______ > Training loss: 0.0178\n",
      "Testing  loss: 0.0191\n",
      "______ > Training loss: 0.0179\n",
      "Testing  loss: 0.0193\n",
      "______ > Training loss: 0.0176\n",
      "Testing  loss: 0.0192\n",
      "______ > Training loss: 0.0177\n",
      "Testing  loss: 0.0193\n",
      "______ > Training loss: 0.0177\n",
      "Testing  loss: 0.0192\n",
      "______ > Training loss: 0.0176\n",
      "Testing  loss: 0.0194\n",
      "______ > Training loss: 0.0176\n",
      "Testing  loss: 0.0190\n",
      "______ > Training loss: 0.0175\n",
      "Testing  loss: 0.0191\n",
      "______ > Training loss: 0.0175\n",
      "Testing  loss: 0.0189\n",
      "______ > Training loss: 0.0174\n",
      "Testing  loss: 0.0192\n",
      "______ > Training loss: 0.0173\n",
      "Testing  loss: 0.0187\n",
      "______ > Training loss: 0.0173\n",
      "Testing  loss: 0.0189\n",
      "______ > Training loss: 0.0174\n",
      "Testing  loss: 0.0189\n",
      "______ > Training loss: 0.0173\n",
      "Testing  loss: 0.0192\n",
      "______ > Training loss: 0.0171\n",
      "Testing  loss: 0.0187\n",
      "______ > Training loss: 0.0173\n",
      "Testing  loss: 0.0191\n",
      "______ > Training loss: 0.0172\n",
      "Testing  loss: 0.0189\n",
      "______ > Training loss: 0.0172\n",
      "Testing  loss: 0.0185\n",
      "______ > Training loss: 0.0172\n",
      "Testing  loss: 0.0189\n",
      "______ > Training loss: 0.0171\n",
      "Testing  loss: 0.0184\n",
      "______ > Training loss: 0.0173\n",
      "Testing  loss: 0.0186\n",
      "______ > Training loss: 0.0170\n",
      "Testing  loss: 0.0186\n",
      "______ > Training loss: 0.0169\n",
      "Testing  loss: 0.0186\n",
      "______ > Training loss: 0.0169\n",
      "Testing  loss: 0.0184\n",
      "______ > Training loss: 0.0170\n",
      "Testing  loss: 0.0190\n",
      "______ > Training loss: 0.0168\n",
      "Testing  loss: 0.0184\n",
      "______ > Training loss: 0.0168\n",
      "Testing  loss: 0.0187\n",
      "______ > Training loss: 0.0167\n",
      "Testing  loss: 0.0189\n",
      "______ > Training loss: 0.0167\n",
      "Testing  loss: 0.0182\n",
      "______ > Training loss: 0.0166\n",
      "Testing  loss: 0.0186\n",
      "______ > Training loss: 0.0166\n",
      "Testing  loss: 0.0183\n",
      "______ > Training loss: 0.0167\n",
      "Testing  loss: 0.0182\n",
      "______ > Training loss: 0.0165\n",
      "Testing  loss: 0.0184\n",
      "______ > Training loss: 0.0165\n",
      "Testing  loss: 0.0182\n",
      "______ > Training loss: 0.0165\n",
      "Testing  loss: 0.0182\n",
      "______ > Training loss: 0.0165\n",
      "Testing  loss: 0.0187\n",
      "______ > Training loss: 0.0164\n",
      "Testing  loss: 0.0183\n",
      "______ > Training loss: 0.0165\n",
      "Testing  loss: 0.0186\n",
      "______ > Training loss: 0.0163\n",
      "Testing  loss: 0.0185\n",
      "______ > Training loss: 0.0163\n",
      "Testing  loss: 0.0187\n",
      "______ > Training loss: 0.0162\n",
      "Testing  loss: 0.0180\n",
      "______ > Training loss: 0.0162\n",
      "Testing  loss: 0.0175\n",
      "______ > Training loss: 0.0161\n",
      "Testing  loss: 0.0184\n",
      "______ > Training loss: 0.0161\n",
      "Testing  loss: 0.0178\n",
      "______ > Training loss: 0.0160\n",
      "Testing  loss: 0.0188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______ > Training loss: 0.0161\n",
      "Testing  loss: 0.0180\n",
      "______ > Training loss: 0.0160\n",
      "Testing  loss: 0.0184\n",
      "______ > Training loss: 0.0161\n",
      "Testing  loss: 0.0179\n",
      "______ > Training loss: 0.0159\n",
      "Testing  loss: 0.0181\n",
      "______ > Training loss: 0.0159\n",
      "Testing  loss: 0.0175\n",
      "______ > Training loss: 0.0158\n",
      "Testing  loss: 0.0184\n",
      "______ > Training loss: 0.0159\n",
      "Testing  loss: 0.0176\n",
      "______ > Training loss: 0.0158\n",
      "Testing  loss: 0.0176\n",
      "______ > Training loss: 0.0158\n",
      "Testing  loss: 0.0177\n",
      "______ > Training loss: 0.0157\n",
      "Testing  loss: 0.0173\n",
      "______ > Training loss: 0.0157\n",
      "Testing  loss: 0.0176\n",
      "______ > Training loss: 0.0156\n",
      "Testing  loss: 0.0178\n",
      "______ > Training loss: 0.0156\n",
      "Testing  loss: 0.0180\n",
      "______ > Training loss: 0.0156\n",
      "Testing  loss: 0.0178\n",
      "______ > Training loss: 0.0155\n",
      "Testing  loss: 0.0176\n",
      "______ > Training loss: 0.0155\n",
      "Testing  loss: 0.0177\n",
      "______ > Training loss: 0.0155\n",
      "Testing  loss: 0.0172\n",
      "______ > Training loss: 0.0154\n",
      "Testing  loss: 0.0180\n",
      "______ > Training loss: 0.0152\n",
      "Testing  loss: 0.0173\n",
      "______ > Training loss: 0.0153\n",
      "Testing  loss: 0.0176\n",
      "______ > Training loss: 0.0153\n",
      "Testing  loss: 0.0173\n",
      "______ > Training loss: 0.0153\n",
      "Testing  loss: 0.0172\n",
      "______ > Training loss: 0.0152\n",
      "Testing  loss: 0.0172\n",
      "______ > Training loss: 0.0150\n",
      "Testing  loss: 0.0172\n",
      "______ > Training loss: 0.0152\n",
      "Testing  loss: 0.0170\n",
      "______ > Training loss: 0.0150\n",
      "Testing  loss: 0.0173\n",
      "______ > Training loss: 0.0149\n",
      "Testing  loss: 0.0170\n",
      "______ > Training loss: 0.0149\n",
      "Testing  loss: 0.0168\n",
      "______ > Training loss: 0.0149\n",
      "Testing  loss: 0.0173\n",
      "______ > Training loss: 0.0148\n",
      "Testing  loss: 0.0168\n",
      "______ > Training loss: 0.0148\n",
      "Testing  loss: 0.0171\n",
      "______ > Training loss: 0.0149\n",
      "Testing  loss: 0.0169\n",
      "______ > Training loss: 0.0147\n",
      "Testing  loss: 0.0168\n",
      "______ > Training loss: 0.0147\n",
      "Testing  loss: 0.0170\n",
      "______ > Training loss: 0.0146\n",
      "Testing  loss: 0.0171\n",
      "______ > Training loss: 0.0146\n",
      "Testing  loss: 0.0174\n",
      "______ > Training loss: 0.0147\n",
      "Testing  loss: 0.0171\n",
      "______ > Training loss: 0.0147\n",
      "Testing  loss: 0.0168\n",
      "______ > Training loss: 0.0144\n",
      "Testing  loss: 0.0167\n",
      "______ > Training loss: 0.0145\n",
      "Testing  loss: 0.0169\n",
      "______ > Training loss: 0.0143\n",
      "Testing  loss: 0.0170\n",
      "______ > Training loss: 0.0144\n",
      "Testing  loss: 0.0170\n",
      "______ > Training loss: 0.0144\n",
      "Testing  loss: 0.0167\n",
      "______ > Training loss: 0.0142\n",
      "Testing  loss: 0.0164\n",
      "______ > Training loss: 0.0143\n",
      "Testing  loss: 0.0166\n",
      "______ > Training loss: 0.0142\n",
      "Testing  loss: 0.0166\n",
      "______ > Training loss: 0.0142\n",
      "Testing  loss: 0.0165\n",
      "______ > Training loss: 0.0142\n",
      "Testing  loss: 0.0164\n",
      "______ > Training loss: 0.0140\n",
      "Testing  loss: 0.0164\n",
      "______ > Training loss: 0.0141\n",
      "Testing  loss: 0.0163\n",
      "______ > Training loss: 0.0141\n",
      "Testing  loss: 0.0171\n",
      "______ > Training loss: 0.0140\n",
      "Testing  loss: 0.0165\n",
      "______ > Training loss: 0.0138\n",
      "Testing  loss: 0.0168\n",
      "______ > Training loss: 0.0140\n",
      "Testing  loss: 0.0167\n",
      "______ > Training loss: 0.0140\n",
      "Testing  loss: 0.0165\n",
      "______ > Training loss: 0.0138\n",
      "Testing  loss: 0.0165\n",
      "______ > Training loss: 0.0137\n",
      "Testing  loss: 0.0161\n",
      "______ > Training loss: 0.0138\n",
      "Testing  loss: 0.0168\n",
      "______ > Training loss: 0.0136\n",
      "Testing  loss: 0.0163\n",
      "______ > Training loss: 0.0137\n",
      "Testing  loss: 0.0163\n",
      "______ > Training loss: 0.0136\n",
      "Testing  loss: 0.0162\n",
      "______ > Training loss: 0.0136\n",
      "Testing  loss: 0.0160\n",
      "______ > Training loss: 0.0136\n",
      "Testing  loss: 0.0158\n",
      "______ > Training loss: 0.0134\n",
      "Testing  loss: 0.0161\n",
      "______ > Training loss: 0.0135\n",
      "Testing  loss: 0.0163\n",
      "______ > Training loss: 0.0135\n",
      "Testing  loss: 0.0162\n",
      "______ > Training loss: 0.0133\n",
      "Testing  loss: 0.0163\n",
      "______ > Training loss: 0.0134\n",
      "Testing  loss: 0.0158\n",
      "______ > Training loss: 0.0134\n",
      "Testing  loss: 0.0161\n",
      "______ > Training loss: 0.0133\n",
      "Testing  loss: 0.0156\n",
      "______ > Training loss: 0.0132\n",
      "Testing  loss: 0.0164\n",
      "______ > Training loss: 0.0132\n",
      "Testing  loss: 0.0162\n",
      "______ > Training loss: 0.0132\n",
      "Testing  loss: 0.0161\n",
      "______ > Training loss: 0.0131\n",
      "Testing  loss: 0.0161\n",
      "______ > Training loss: 0.0132\n",
      "Testing  loss: 0.0158\n",
      "______ > Training loss: 0.0131\n",
      "Testing  loss: 0.0158\n",
      "______ > Training loss: 0.0131\n",
      "Testing  loss: 0.0160\n",
      "______ > Training loss: 0.0130\n",
      "Testing  loss: 0.0157\n",
      "______ > Training loss: 0.0129\n",
      "Testing  loss: 0.0159\n",
      "______ > Training loss: 0.0129\n",
      "Testing  loss: 0.0158\n",
      "______ > Training loss: 0.0129\n",
      "Testing  loss: 0.0158\n",
      "______ > Training loss: 0.0128\n",
      "Testing  loss: 0.0157\n",
      "______ > Training loss: 0.0129\n",
      "Testing  loss: 0.0152\n",
      "______ > Training loss: 0.0128\n",
      "Testing  loss: 0.0158\n",
      "______ > Training loss: 0.0127\n",
      "Testing  loss: 0.0157\n",
      "______ > Training loss: 0.0127\n",
      "Testing  loss: 0.0155\n",
      "______ > Training loss: 0.0126\n",
      "Testing  loss: 0.0160\n",
      "______ > Training loss: 0.0126\n",
      "Testing  loss: 0.0159\n",
      "______ > Training loss: 0.0126\n",
      "Testing  loss: 0.0152\n",
      "______ > Training loss: 0.0126\n",
      "Testing  loss: 0.0156\n",
      "______ > Training loss: 0.0125\n",
      "Testing  loss: 0.0155\n",
      "______ > Training loss: 0.0125\n",
      "Testing  loss: 0.0156\n",
      "______ > Training loss: 0.0124\n",
      "Testing  loss: 0.0150\n",
      "______ > Training loss: 0.0124\n",
      "Testing  loss: 0.0158\n",
      "______ > Training loss: 0.0125\n",
      "Testing  loss: 0.0154\n"
     ]
    }
   ],
   "source": [
    "for e in range(num_epochs):\n",
    "\n",
    "    train_targets, train_preds, train_loss = loop(train_loader, training=True)\n",
    "    writer.add_scalar('data/train_loss', train_loss, e)\n",
    "    writer.add_scalar('data/train_accuracy', accuracy_score(train_targets, train_preds.argmax(axis=1)), e)\n",
    "      \n",
    "    test_targets, test_preds, test_loss = loop(test_loader, training=False)\n",
    "    writer.add_scalar('data/test_loss', test_loss, e)\n",
    "    writer.add_scalar('data/test_accuracy', accuracy_score(test_targets, test_preds.argmax(axis=1)), e)\n",
    "\n",
    "    train_loss /= train.shape[0]\n",
    "    test_loss /= test.shape[0]\n",
    "    \n",
    "    epoch_train_loss.append(train_loss)\n",
    "    epoch_test_loss.append(test_loss)\n",
    "    \n",
    "    print('______ > Training loss: {:.4f}'.format(train_loss))\n",
    "    print('Testing  loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAIABJREFUeJzs3Xd0VNX2wPHvmfTeCYQQktB7C116ESxgA1GxK/bns+BDffIs+LMXfFZ8Yi+IFaQJSkdKaNJDqAktBRLS6/n9cWaYEAIEUiZlf9bKmpl779ycccnsnLa30lojhBBCWBzdACGEEDWDBAQhhBCABAQhhBBWEhCEEEIAEhCEEEJYSUAQQggBSEAQQghhJQFBCCEEIAFBCCGElbOjG3AhgoODdWRkpKObIYQQtcr69etTtNYh57uuVgWEyMhIYmNjHd0MIYSoVZRSB8pznQwZCSGEACQgCCGEsJKAIIQQAqhlcwhCCHGhCgoKSExMJDc319FNqXLu7u6Eh4fj4uJyUe+XgCCEqNMSExPx8fEhMjISpZSjm1NltNakpqaSmJhIVFTURd1DhoyEEHVabm4uQUFBdToYACilCAoKqlBPSAKCEKLOq+vBwKain7N+BIT1n0Pc745uhRBC1Gh1PyAUFcC6/8GPd0JynKNbI4SoZ9LS0nj//fcv+H2XXXYZaWlpVdCis6v7AcHJBcZ9A85u8M1YSD/k6BYJIeqRswWEwsLCc75v7ty5+Pv7V1WzylT3AwKAfxO44TvISoFPhsHcJyDtoKNbJYSoByZNmsSePXvo3Lkz3bt3p1+/fowaNYq2bdsCcNVVV9GtWzfatWvHtGnTTr0vMjKSlJQU9u/fT5s2bbj77rtp164dw4cPJycnp0raWn+WnYbHwC2/wKJnYcPnsOV7EyQiejm6ZUKIavLc7G1sP3yyUu/ZNsyX/1zZ7qznX375ZbZu3cqmTZtYsmQJl19+OVu3bj21NHT69OkEBgaSk5ND9+7dufbaawkKCjrtHrt37+bbb7/l448/ZuzYsfz444+MHz++Uj8H1Jcegk14DNz2G9y3Clx9YP4k0NrRrRJC1CM9evQ4bZ/AO++8Q6dOnejVqxcJCQns3r37jPdERUXRuXNnALp168b+/furpG31p4dQUlAz6PcI/PYIHPwLmvZxdIuEENXgXH/JVxcvL69Tz5csWcKiRYv466+/8PT0ZODAgWXuI3Bzczv13MnJqcqGjOpXD6GkjuPAIxB+vhdWvAXFxfZzm76FeZMc1zYhRJ3h4+NDRkZGmefS09MJCAjA09OTnTt3snr16mpu3enqZw8BwNUTrvoAlr9h5hUyk2DgJECZoaTcdBj0JLj7ObqlQohaLCgoiL59+9K+fXs8PDwIDQ09dW7EiBF8+OGHtGnThlatWtGrl2PnNJWuRWPoMTExutIL5GgN856AtdbZ/aAWkGodw7vpB2gxrHJ/nxCiWu3YsYM2bdo4uhnVpqzPq5Rar7WOOd976++QkY1SMOIVGP8jXPIoZByF5kPB4mzmFzKOmetiP4WV75z9PsXFEDsdcqp3I4kQQlSW+jtkVJLFYoJA86Ew4AlQTvDpCBMElr8Bw56Hpa9CfhY0HwKhZUxMHVhpnaReA9d8VP2fQQghKkh6CKW5eICzK0T0hpzj5tjCyZCfCc7u8Pu/y16qemCVefz7O9i71KTMyEqpvnYLIUQFlSsgKKVGKKV2KaXilVJnLL9RSrkppWZYz69RSkVajw9TSq1XSm2xPg62HvdUSs1RSu1USm1TSr1cmR+qUnQYY3oMY78wrxvHwNBnYc+fsPjFM4PCgZUQ0hq8QmDjl/DXu/BOF8jLrO6WCyHERTnvkJFSygl4DxgGJALrlFKztNbbS1x2J3BCa91cKTUOeAW4HkgBrtRaH1ZKtQcWAI2t73lda71YKeUK/KGUGqm1nld5H62CwjqbeQWAka9BeDcI6wrHtsCy12DLTPBqACEtocvNkLAWut0GJxMhMRYyj0HeSdi/HFqNdOhHEUKI8ihPD6EHEK+13qu1zge+A0aXumY08Ln1+Q/AEKWU0lpv1Fofth7fBngopdy01tla68UA1ntuAMIr+mGqTM8J0LibmYC+YiqMehdC2oCLO2z7FaZfCoU5ZoNb4xg4sc/MJQDEL3Js24UQopzKExAaAwklXidi/yv/jGu01oVAOhBU6pprgQ1a67ySB5VS/sCVwB9l/XKl1ASlVKxSKjY5Obkcza1iTs7Q9Wa48Tu4dTY8thN6TICAKIi8BMK7m+uK8sDFC3YvlPQYQtRjF5v+GuDtt98mOzu7klt0dtUyqayUaocZRrqn1HFn4FvgHa313rLeq7WeprWO0VrHhISEVH1jL5SbN1z2Gjy8CTwDzVCTcjLnet0LaQfg2FbHtlEI4TC1KSCUZ9npIaBJidfh1mNlXZNo/ZL3A1IBlFLhwM/ALVrrPaXeNw3YrbV++yLaXjO5ekFoW7MfodcDsO4Tkwbjtt/MPEPKLuh6i6NbKYSoJiXTXw8bNowGDRrw/fffk5eXx9VXX81zzz1HVlYWY8eOJTExkaKiIp555hmOHTvG4cOHGTRoEMHBwSxevLjK21qegLAOaKGUisJ88Y8Dbix1zSzgVuAv4DrgT621tg4HzQEmaa1XlnyDUmoKJnDcVbGPUAMNfxEK88ArCIY9B7Mfhq0/msptCWug+TDwbWSu3bfMLFFtPsSxbRaiPpg3CY5uqdx7NuwAI8++ULJk+uvff/+dH374gbVr16K1ZtSoUSxbtozk5GTCwsKYM2cOYHIc+fn58eabb7J48WKCg4Mrt81ncd4hI+ucwIOYFUI7gO+11tuUUs8rpUZZL/sECFJKxQOPAralqQ8CzYHJSqlN1p8G1l7D00BbYIP1eN0JDNEDoOVw87zLLRDU3GxwO7gadDFs/sac278CvrwGvr/V5E4qKXWP2c8ghKgzfv/9d37//Xe6dOlC165d2blzJ7t376ZDhw4sXLiQf/3rXyxfvhw/P8fkUCvXTmWt9Vxgbqljk0s8zwXGlPG+KcCUs9xWlb+ZF09rzey/j+Dj5syg1g2q41eezmKBLuNNAj0Avyaw8StodTnMGA/eDeDkIdjwBfR5yP6+Wf+AQ+thYrwp5tP+OnD3rf72C1GXnOMv+eqgtebJJ5/knnvuOePchg0bmDt3Lv/+978ZMmQIkydPLuMOVavO71QuKta8vziep3/eQnb+uWuYVplON5iJZv+mMHwKHN8LH/QGlJlbiOwHqz+AImv7kuPgwAqzlHXuRJMSY93/HNN2IUSFlEx/femllzJ9+nQyM82G1UOHDpGUlMThw4fx9PRk/PjxTJw4kQ0bNpzx3upQ53MZOTtZeOGq9oz58C/++2c8/xrRuvob4dMQBj9tegftrgLXH2DVOzDoaQiMhu53wcxbYe9i2P4rJO0wyfWc3e3DS9t+hn6PVn/bhRAVUjL99ciRI7nxxhvp3bs3AN7e3nz11VfEx8czceJELBYLLi4ufPDBBwBMmDCBESNGEBYWVi2TyvUm/fVj329m1uZDzHu4P80beFdyyyqoIAdea2FWKGUeNcGg/XVmL8O2n8EvAtIPwkMbTLU3IUS5SfprSX99hicva42HixOTf91KjQuCLh7Q5koTDMJ7wFOHTfGeTjea3EjXTTfXbfvp3PfJPg4f9Ycjf1d9m4UQdU69CQjB3m5MHNGaVXtSmbEu4fxvqG5dxpuewdD/gLObmYxuOdxMKjfpDhF9YPN3ZtdzUaGpzTBjPBzeaL/HgVVwZDPEzXfc5xBC1Fp1fg6hpJt6RDBvyxFe+G07HcL9aBdWg8pjRvaFSQfNsFFZuoyHX+83+xhS4mDhM+a4TxiEdTHPbcHh8Kaqb68QtYjWGqWqZWGjQ1V09KPe9BAALBbFa2M64e3uzDXvr2Lh9mOObtLpzhYMANqOBldvWP+Z2eQWGG16DYfWw+KXYNpA8xzgiAQEIWzc3d1JTU2teUPFlUxrTWpqKu7u7hd9j3ozqVxSSmYet3+6jsQT2Sx8dADB3m6V0LpqMP9JszxVKej3GBTmwpqPTBruk4mAAicXKMqHx+PBuwbmfhKimhUUFJCYmEhubq6jm1Ll3N3dCQ8Px8XF5bTj5Z1UrldDRjbB3m68ObYTl7+zgkk//s1HN8fgZKkF3cnB/zbzA8f3QvtrIXmn+fI/mWi9QJvJ6a0/mrmEFkMd2lwhagIXFxeioqIc3YxaoV4NGZXUItSHpy5rzaIdSTz105ba0Z109YJx38Cl/wcN2pgaDTZtrFlEut5qHktONgshRDnUyx6CzW19o0jJzOfdxfF0jwrkum41t0bPKQ3amB8wG928QsC3MVz+hqnFENnPFO85uOr09235AaIGmBVMueng3+TMewsh6rV6HRAAHhnWkrX7j/PsrG0EerkwuHWoo5tUfkqZ6m0eASYnUt9/mONR/U1upMJ8sDhBxhH48U6TKyn7OGyfBff/JUFBCHGaejtkZONkUbx1fWca+rlzx2exPD5zM7kFRY5uVvm1GgERPU8/FtXf5EGaMR7ebGOyrALsXQK7f4f8DJj9D6nkJoQ4Tb0PCACN/T2Y+49+PDS4OT+sT+SeL9fXjjmFs4m8BJQFdi+AzGOwdpo5fnQLZCWb3dB7/oTEiq/YEkLUHRIQrFydLTw2vBXPjWrH0rhkPlmxr/YGBQ9/aNQZ3HxNltWENeDsYT8/+l2wuMD2XxzXRiFEjSMBoZRbejdlUKsQpszZwfXTVnM8K9/RTbo4o9+DW36xr0RqdxW4eEGDthDSCpoNNplVtYbiIlO1TQhRr9X7SeXSlFJ8ML4bM9Yl8OLcHdz1+Tq+vLMnXm617D9VaFvzGD0AEteaFUiNu5lU3GACxO4FsHAy7PzNDDENmGSyq3oFwyWPQKCs3RaiPpEeQhncXZy4tU8kU6/vzMaENEZOXc7iXUm1cwipzZXg5meWnPa427wGs28hqr+py1BcaOYWfroLDsXCpq/NcSFEvVIvU1dciDV7U5n4w98cPJ5Nx3A/Hh/eiv4t61BKiPRD4BkIaQdNDeeuN8NPd5sJ50e2m6yrJaXugfhFZqlrx7GOabMQ4oKUN3WFBIRyyC8s5qcNiby3JJ7EEzlMHdeFT1bso3WoDyM7NKRjuD+BXq7V3q4qs+lb+OVeuOsPCG1n6jXYfDTAnjzvke3g19i+fLUeZJMUojaSgFAFMvMKGTl1GQnHc/B0daKoWJNXWIy/pws/39+XqOBzZCutTbKPw2vNzaa2ogKzM7rzTdBsEHzQx9SI3vytmbjuMh6+vAZ8G5nXQogaRyqmVQFvN2feHNuZ5g28+eTW7qx9aihf3NEDBdz5+brataHtXDwDIeYOM+/Qf6JZvvr70/D5KEDBkMkmw+qeP035z31LYdM3cOJA2ffTGhLWykY4IWo4CQgXqHtkIIseHUDvZkH4ebrQv2UIb17fmb3JWczefNjRzas8l78O43+AwU/DnQtg0NOQnWI2vfmGmWWre5eYrKrFhaCLYc2HZd9r11z4ZJgJHGWJ/+PswUQIUW0kIFSCgS1DaBnqzcfL93LN+yt5f0m8o5tU+fpPhGEvwPAXzOtmgyE71b4LOqo/rP8cMpPOfO+ueeYx/o8zz2kNM26GZa9WTbuFEOUmAaESKKW4uVdT4o5lsuFgGq/O38U3aw6SlJHLvpQsHvhmA+sPnHB0MytGKZM8z1aus9VIcPUxtRd8wuDyt0zBnuVvnP4+re2BoKweQs4JKMiC5F1V234hxHnVst1WNde13cI5kJrNFZ3CeOaXrTz18xae+hksCoo1JJ3MZea9fRzdzMrj7muWqK5+Hxp3heDm0OUmWPeJ2eMQ2ddcl7QdMg6bkp9H/jYT1p6B9vtkHDWPybtM8JCVSkI4jPQQKomnqzP/vqItnZv4M/Pe3syY0IvJV7Tl7v7R3DMgmnX7T7DxYC3vJZTWY4LJiRTR27we8h/zxf/1GDi61Rzb+LX13GRAm3mHkjKs8y55J02a7rLIZLQQ1UICQhVwd3GiZ3QQd1wSxZMj2/DQ4Bb4ujtzz5fr+XjZXpIycnl+9nYOp+U4uqkVExgFD64zgQFMyotbZ5u6zn9OgZ1zYfV7popb6yvALwIW/59ZmWRzskQQSN555u9Y+ip8eInJtySEqFISEKqBt5sz02/rTotQb16cu4MBry5h+sp9vLZgF1rr2pkSwyYwCpxLbMrzCYXeD0LcPJh5KzTqBCNfNUFi1FRI3Q3LXrdfbxsygrLnEfYuhWNbze7osmgNG786PbAIIS5KuQKCUmqEUmqXUipeKTWpjPNuSqkZ1vNrlFKR1uPDlFLrlVJbrI+DS7ynm/V4vFLqHaXq9uBxTGQgX93Zk6cva0OYvzvD2oby66ZDjJy6nGFvLWNzQpqjm1h5ek4wpT0bdYKbfwEXd3O82WAzvxD7CRTmmWMZh00aDI/AM3sIWkPSNvN83f/K/l3bf4FfH4Clr1TNZxGiHjlvQFBKOQHvASOBtsANSqm2pS67EzihtW4OvAXY/nWmAFdqrTsAtwJflnjPB8DdQAvrz4gKfI5aQSnF3f2j+eOxgbx0TQfcXZxIzconO6+QsR/9xcHUbEc3sXK4+8FD6+GOBadPIAPE3G5WFu38zbw+ecSsUgppbXoI+dmw7DXzmHHUXOsbDrsXQuz00+9VkGOytQJQi3tZQtQQ5Vll1AOI11rvBVBKfQeMBraXuGY08Kz1+Q/Au0oppbXeWOKabYCHUsoNCAR8tdarrff8ArgKmFeBz1KrBHu7Mf/h/vh7uZCdV8TgN5bw5M9/0yrUlyaBHlzRMQyLgr8T0xnYKoRa14Fy9yv7eNRAM5ew/E3wDDITyb6NwC8ctv0CcfPN/IO7v5mgBrj8DdND+O0R8G8KzYeY4/F/mKR8AFkpVf6RhKjryjNk1BhIKPE60XqszGu01oVAOhBU6pprgQ1a6zzr9YnnuScASqkJSqlYpVRscnJyOZpbe0QEeeLr7kJDP3ceGtyClfGpfLl6P8/N3k7fV/5k4OtLuP2zdczZUofGxy0Ws+Io7SB8MRqObQOfRqaHkJtm36uw8UuzZBWgSQ8Y+wWgTi/7eXgDWJzNKqeScxFCiItSLfsQlFLtMMNIwy/0vVrracA0MMntKrlpNcaE/tG0buhDt8gAjqbn8unK/ZzMKWBPcibPz97Ot2sPMjamCaM7lxk3a5eOY8zGtqkdzW5nn0amihvA9lnm8chmM4fg3dA+7OQfASklJp4PbzSJ9/ybwoGV1fsZhKiDytNDOAQ0KfE63HqszGuUUs6AH5BqfR0O/AzcorXeU+L68PPcs15xsigGtW6Ar7sLLUN9eOmaDrx3U1devLoDx7PyWbfvBC/N3Ul+YbGjm1o53Lyh533mua+1hwCQc9wk1fMMgqN/2yu/gQkayXHmudYmIIR1MSubMo+Z3sP6z879e4uLZF+DEGdRnoCwDmihlIpSSrkC44BZpa6ZhZk0BrgO+FNrrZVS/sAcYJLW+tSfcFrrI8BJpVQv6+qiW4BfK/hZ6qRuTQPYMHkY027pxtGTuXzx134Op+Ww8+hJnp21jZ1HTzq6iRev5wToMAaiB5legpuvOd60LzwYC9d+Ape+ZL8+uCWkxMG8SfDpSDPh3Kiz6UUU5ZsJ5tkPw8HVZf++glx4vSVsmVn1n02IWui8Q0Za60Kl1IPAAsAJmK613qaUeh6I1VrPAj4BvlRKxQPHMUED4EGgOTBZKWVbDjJca50E3A98BnhgJpPrzYTyhfJ1d2FAyxDahfkyZc4OpszZcercqj0p/PZQP1yda+GWEnc/uLbEctKQVpC4zvQKPAOhw3WnXx/SCoryrFlVrX/lh3WBE/vN84Q15nHuRJiw9Mxqb2kHTcbWY9uq4tMIUeuVaw5Baz0XmFvq2OQSz3OBMWW8bwow5Sz3jAXaX0hj6zOlFF/f1ZNVe1I5mVNAQbHGy9WJR7/fzEvzdtCvRTBfrz5Ii1AfekQF0KdZMO4uTo5u9oWxBYQGpVc1WwW3tD7RED3Q5EYKbWeS6oFJwx3Uwgw1JW2Dhh1Of79tRVK2rEgSoiyS3K4W8fd05bIOjU47tjkhjU9X7ufTlfsJ9nZjaVwyHy7VNAn04I0xnekRFXiWu9VALS6FlN0QEFn2eVtA8GsC4382w0TObuAdar+m6y2w8BnTCzgjIOw3j1mpld1yIeoECQi13LOj2tE81If4Yxn8a2RrFIqV8Sk8/9t2HvxmA6smDcbZqZYMJ7UdZX7OxjMQGneDNlea4SCLdQe0T0P7Ne2uMvsYjm098/3SQxDinCQg1HK2WgwlDW0bigbu/iKWP3YmMbRNKK8t2MXVXRrTqqGPYxpaWe7+88xjrl6mNoOzq+k9NGhtz7ZakmxiE+KcJCDUUYNahdDQ151v1hwkPbuAD5fuYV9KJh/dfN4627WTb5j5UQpC25tUF2DSWxQXmWWup3oIMmQkRFkkINRRzk4WbuoZwRsL41i9NxWLgoXbj3EkPQdvN2fSsgtoEuhJcbHGYqllaTHKctUH4Gbt/YS2h01fQ1oCzLgJXLzgjnn2us15J01yPWc3x7VXiBpIAkIddv+g5uQUFDF95T5eH9OJx2Zu5op3VnA8Ox+A927syivzd9I0yIt7+kez+1gGcUmZPDasJUHetezLMryb/XloO/P41bVmZ7OymNQW2Skmj1L6QdNL8A0r+16ZybDoP3Dp/4GHf9W3XYgaQgJCHeZkUTwxojWPDmuJs5OFXccyiDuaQecmAfy0MZH7v96Aq5OFpJN5LIuz54k6kpbDJ7d2r709h/AYaDEcDm0wm972Loa/vzfnGncxASErxR4QSpfu3PS1+Wk54tyT3ELUMRIQ6gHbKqMnR7Y5daxXdCC3TF/LU5e1YWjbUPYkZRIV7MXiXUlM/nUb361L4MaeEY5qcsW4esFN1t3I+dnwcgT89a553fQS2P6rfaXR8X0w/VIY8AQ0jgFdDDusG/FTShXsKSowhX6EqKMkINRTPaOD2DR5OB6uZvNaY38PAG7u1ZTfNh/h7UVxeLk5kZKZz52XRDmyqRXj6ml6DAf/Mn/xRw80x08ehuzjJvdR5jGzu1lrM69g2+hmy5sEEPe7qQD3z63gFWQ/Hzcf+v6jGj+QEFWnlixQF1XBFgxKUkrx+KWtSMrI4+HvNvHCb9tZsTuFpJO5FBfX0qRwzQaDxQWGTzF1nwHmPgFvtTcBodlgsymux93g3cCcD4w2PYScE5CXaYadCrJP7zWs/chsgss+Xu0fSYiqID0EcYYeUYHc1icSi1L8sfMYd32xjtyCYsIDPLi9bxQ39YyoXWkx+vwDOo41O6CLi0E5QUGWmWwuyDJZV1taM7P3ut/UWUhYBxs+h+kjTEoN296FtASwbfs4vMk8pieAiwc4u58+FyFELSMBQZTp2VFmpc7QNg14ce4OhrQJZfXeVF74bTs/rk9k5r298XKrJf/7uLjb02FYLGbHc1Yy3PIrpB+C5kPt1wZGmZ/cdNMjSN5p9i8oa2c63bqXoajAvhs6ZTd8PgqGPAPd76q2jyVEZasl/6KFo/RpHsycf/Q79Xr+1qPc//V6RkxdxsmcQt4c24khbULPcYcayL+pKawT1f/s1wS3sj8vKFHrOs1aPDB5p32uIf4PU+1ty4/lCwgZR8EzGJzkn5+oWWQOQVyQEe0b8sJV7XF3diLI25X7v97Akl1Jjm7WhRn3jbUk5znYKrh1ugGcrHsyXH3su51tw0UAe/4wjwmrzXyC1mbeoSz52fDfbrDhs4tuvhBVRQKCuGA39WzKwkcH8MO9fYgK9uL2z9bxv+V7T51PPJFdsyegfULBI+Dc13gFw40zYcRL0LSPCQrRA0xA+HgwzJ9kAkRQC7NKCcyS1d0Lzcqj15qbDW6lpSdCfiYk7az8zyVEBUmfVVy0QC9Xfrq/D4/P3MyUOTs4lJaDn4cLby/aTf+WIVzXLZw2DX1oEVpLE+rZJpqHTDbzBMe2wM7fzDH/CGg+zBTnSd0Ngc0gLwN2/w7+TaAwxwwreYecfs9065BTeqJ5PLAKZv8T7loE7r7V8rGEOBsJCKJCPF2d+e8NXQn02sqnK/cD0DMqkNV7U1kWl0yTQA+WTRyEqs2rbxp3NT9r0s1r5WQqsnkGmpKdYGpCKwVHNpmEegBpB4B+p9/rpLV0uC0gbPzKLGVNjTe/ozKkJ5rJ8oielXM/UW9IQBAV5mRRTLmqA7f3jWLroXSu6BjG8ax8ftqQyEvzdrIpIY0uEQEUFWssitobHPytO7eb9jHBAEy6bTBzDs5usHOOPSDYkumVZAsE6QlmCWzcAvPaNuxUGZa/ATtmw8T4yrunqBckIIhK0yzEm2Yh3gCE+LhxgzXb6vSV+3Ffc5Df/j5Ckdb0bxHMf65sR5NATwe3+AIFRpvHNiXyG9mCREgra7ZVbe8FpJUVEKznctNg31J7Co2Mo5XXzqwUs6y2qFBWMokLIv+3iCrj6+7CoFYhzN58GA8XJ0Z1CsPTzYkZ6xK47sNVLJ04qHZtcAtpafYuNO1rPxbeHYKam16DLjWRfuIArP8cDm8EF0+TkdU2hwAQ+4nZ36D1+XsIO+dAwhoY9rz92PynzFzFFW+dfm1umnnMOW7feS1EOUhAEFXq4SEtaRLgyV39omnoZ0peDmsbyo0fr2FmbAI3944kOSMPPw8XXJ1rwaK36IGnvw6MgofWm+dag5sf5KVDg3aQtAN++ye4ekNxIax+D9z9wKcRZByBnXMhojck7zI9hIJckzzPUkaQ3PytuX7Qv+HoFjM8teYD8As/89pc61xHdqoEBHFBasG/QFGbtQ3z5d9XtD0VDAB6RwfRrWkAHy7dyy8bD9Hv1T959PtNZ7w3OSOPjNyC6mxuxSgFDdub582HmMCgi+HW2XDvCnM8Nx2aWCd7dRG0vNTUhM44Cu/3gsUvln3vE/vN9bvmwP8Gw8eDzL0zjp3ZM8mx9hCkVKi4QNJDENVOKcXES1tx26dr+eeMTbi7WPjt7yM4Wzay7fBJukYE4OpsYUZsAl2a+DPjnt6ObnL5tbzUDAM1aGte+4ZDo04mWDRoC0nbTfa+HO4kAAAgAElEQVTVHbOtAWEk7F1qVidlHIHts8wy15K0tk9Qb/zaPLp4mN3OGYdNAj7bJDeU6CFIQBAXRnoIwiF6RQexbOIgnrqsNQv+2Z8QHzd+2XQYPw8XFmw/yjdrDxId7MWafcdZs7cW1UDu+zDc9hsEWDPgtb7MnvCu9RXm0b+pKc4TEAXBLaw9hCPmXOpus/kt4xjMvN38lZ9zwpT9BNjzp9kQN3EvDH/BHCs5/1BcbL9WegjiAkkPQThMA193JvRvBsBnt3cnPaeAPs1MemqtNXmFxVzyymImfLmeQC9X/jm0BaM6hdWOZasNO0BkP+h6q/1Y5xsgfqHpIfR92PxVrxR4l8oFFf+H2c287SeI6GUK99joItPjcHK2V3zLOGJyM+1eBMHNzVASQEocvN4Kxn5u7gOQnwVLX4UB/zK1IoQoQXoIokZoF+Z3KhiAGVZyd3HiP1e2pUuEP15uTjz83SZGTl3O5oQ0B7a0nNx8TE/BNqcAZtnqhCXmi7zH3dD+WnPcp5F59I8A38Ym/cWueebYrrlwYp957mudQA7rbB5tgSTjqNkl/fV1sPxN+++LXwSZRyFhrf3Y/pWw8m2zQ1qIUiQgiBrtyk5hfHZ7D3594BJevbYjKZn5vDhnh6ObVbl8rF/sDTtCh+tMEDj4lxka2r8Cjv5tzttSaTSyBgSfhuYx46h1eEibFUg2x635pWwJ+cAsRQWZXxBlkoAgagUni2Js9ybc3jeStfuPM33FPp7+ectpSfSKizUFRcUObOVF8rZ+sYe2h/4TTY9BF8Pgp81y1Y1fmd5ARG9Amf0MYGpHu/magJBzwhxLtiXNKzGsVnLvg+06mV8QZZCAIGqVa7uGY1Hw/G/b+XrNQVbvs084vzRvB5e+vYyimpxptSwhLc1wUothZqjpmo+gy83Q/W6zRDU71RT4aX8t3P+Xfcc0mF5C5lH7X/622g2+je3XlOwh2Mp9ZpWRiVXUe+UKCEqpEUqpXUqpeKXUpDLOuymlZljPr1FKRVqPBymlFiulMpVS75Z6zw1KqS1Kqb+VUvOVUsGl7ytEaQ393BnZoREtQ73xdnPmx/WHmBmbwOG0HH7ccIi9yVms2lPL/vr1CIB/bDSTzWAK94x+10wc3/wzdLsNOt9oNqw1aHP6e71DTQ8h+8Tpx4Oa2Z+nJdj3KsiQkTiH864yUko5Ae8Bw4BEYJ1SapbWenuJy+4ETmitmyulxgGvANcDucAzQHvrj+2ezsBUoK3WOkUp9SrwIPBspXwqUadNvb4zFqV44se/+WF9Ij9uSKSRnzvHs/IB+OKvAxw6kcPI9o34bt1BCoqKeXBwCwe3+iK5esGVU89+3qeRSWlh+6K3CWpmciX5Nja5lX6aYFY0FRea81m1aCmvqDbl6SH0AOK11nu11vnAd8DoUteMBj63Pv8BGKKUUlrrLK31CkxgKElZf7yUWUPoCxy+2A8h6hdnJwsWi+LGnhF4uDgxuHUDjqTn4u3mzJhu4SzcfoxJP23hmg9W8tK8nby7OJ7s/EJHN7tq+Nh6CCW/4JW9hnSzweZxy/dmhVF5howyk+xZWUW9Up6A0BgoMStFovVYmddorQuBdCDobDfUWhcA9wFbMIGgLfBJWdcqpSYopWKVUrHJyTLuKey6RgSw5dnhfHxLDP1aBDOuexMeHtqC2/pE8tRlrdmTnIW/pwu5BcUsi0uu2VXcLpZvYyjKM/UUbNz9TE1oJzdofbn9eMYR+1DRuYaMfrgDvrr2zOMJa2Fdmf9MRR3hkI1pSikXTEDoAuwF/gs8CUwpfa3WehowDSAmJqYO/osWFeHsZP6m+fJOezGYZ0e1A6BTuD9NAj257J3lvDRvJxNn/s20W2Lo3eysf6vUPrb020c2g5MrFOWbgNDyUnh8l9m5bKOLIMUaOM42ZJSVAgdWmlVOx/eePoEd+yls/xW631k1n0U4XHl6CIeAJiVeh1uPlXmNdX7ADzjXIGVnAK31Hq21Br4H+pSzzUKUS8/oIML8PRjaJpQDqdlkFxTx9M9byCssOnVNek4B//5lC4fSchzY0gqwBYTUeNMrAPDwN/MFHgFmN7Sbn72GdKH1c+ZnmOyqpcXNt+903r3o9HPZqVCQBXmZlf85RI1QnoCwDmihlIpSSrkC44BZpa6ZBdj26F8H/Gn9oj+bQ0BbpZSt4OwwoI7tNhI1xaPDWjLlqvb875YY9qZk8ej3m9l59CQbD57g8Zmb+Wr1QX5aX0vHzP1K/K3mEwpeIaaHYKMU3DQTrp5mP2bb8VzWsNHOOeZ8YLRJs1GSbZ4iK6ly2i5qnPMOGWmtC5VSDwILACdgutZ6m1LqeSBWaz0LM/7/pVIqHjiOCRoAKKX2YyaNXZVSVwHDtdbblVLPAcuUUgXAAeC2yv1oQhhh/h6M72WSzT05sjUvz9/JnL+PnDrv6mzhr72pXNEpjKy8Qto39jvbrWoeD397DQaPQLN5zZZYzyai5+lDRMEt4GSiGR4qWU8h54TJo9TtNpOxdf2nphyoi4c5bwsImcmnDyWJOqNccwha67nA3FLHJpd4nguMOct7I89y/EPgw/I2VIjKcM+AZnRrGkDiiRx83J2xWBQrdqfw5eoD3Dp9LYfScphyVXtu6BHh6KaWn38EHNtihodGvlL2NZ6BZpK5KA+CW8LexaaHUFxshoicnOHvmeZ8l5tMsFjzgUmdETUAnF3tK5Qqs/6zqFFkp7Kod2IiA7mqS2OGtAllUKsG9I4OIr+wmIPHs4kO9uLJn7awYnct2rhlm0fwCDz7NUqBrzWJXrB1T0ZWCsyfBB/1MxvXNnxhMqk26mTKhLp4wobP4Y2WZkI5z1pnIfOYCQ7nHBUWtZEEBFHv9YgOxKKgdUMffn2wL80bePPYzE38ufNY7UiD4W+dR/A8R0AAezqL4JbmccdsWPc/U7QncZ3pZXQeb865uJsd0ztmm6GkPX/a73NoA7zeEuIWVO7nEA4nAUHUe77uLrx8TUdeu64Tnq7OTB3XmaJiuOOzWEa8vYxpy/aw48hJRzfz7E71EALOfZ2tfkJAJHS9BXb+ZpaigukdAET1s1/fYpj9+eESJU7j5kNxgdkhLeoUKZAjBDC2u321TrswP1ZNGsz8bUeZuiiO/5u7E3eXOJZNHEQDX/dz3MVBLjQgeATAFW+bLKvObvDnC7DtFzNEZOs9gEmmlxxn9jgkrLYft6XJOJVZVdQV0kMQogyuzhZGdQrjj8cGsvCR/hQWad5bbN8NnHA8m/ikGrIeP3oQ9P0nND3PVp6O18PAJ01GVYuTSa/d7zETIPIzTD0Gi5P9eo8AuOxVM6dgYyvmA2aoqTKk7IZd8yvnXqJCJCAIcR4tQn0YE9OEb9YeJD4pk/zCYm7+ZA03f7KGwppQf8HNG4Y9Z18eejah7WDgJHuNZzDPG5id3acqsZXmX2KvQ8lsqyf2m5KcFfXnFJh5KxQVVPxeokIkIAhRDo8Ma4GXmzOPzdzMR0v3sD81myPpuSzeVQfya4W2NY9hXco+719iCW5Ia/PY2FqkJ3lXxX//oQ1QmCtDUDWABAQhyqGBjzvPj27P5oQ03lgYR8+oQEJ93fh6zQEAVu1JOZV+u6SkjFxyC4rOOF6j2AJB45iyz9t2Q7v52VcqdbBuO0oqI8HAiQOQUc69CplJkG4t4FNy4lo4hAQEIcppVKcwfrq/D1PHdea/N3bh+u4RLI1L5qcNidz48RrGfLiKpAx7fqDMvEKGv7WM/5tbw7OydBgLdy+G4OZln7f1EDwDTfDwamAmnJ094I/n4Y8XoLBEMPz6Opj1oHmelQpvtIGDq8+8L5jegc3hjRX/LKJCJCAIcQG6RgQwunNjGvi4c2vvprg7O/H4zM34uDlzOC2Xfq8s5r6v1vP7tqP8uD6RtOwC5m89yrlTezmYkzM07nr2855BZgWSZxBE9oWJu8G7AVz9oZlwXv46fDLM5EFKS4CUOBMAiovM3oaMwyaDalkOrTdpMsK6whHpITiaBAQhLlKQtxs3925KsYbb+kby8wN9GNe9Cev2H2fCl+uZMmc7rs4WkjLy2HqoBu9jOB+lILCZfaezTbur4KbvYcxnJs/Rdzeanc8AeSfNnMDxfeZ16l6zhLX0sNChWGjQ1qyQOrq14hPLWbVoh3kNJAFBiAq4b0Az7rwkirv6RdO6oS/PjW7P6ieH8OTI1liU4oXR7VAKFu2o5fl/xnwKl75U9rl2V5ua0AGRZrObk5s5nrDW1FQAOL4HfnsEvrvJnvIi+7jJlRTZzwxFFeWVPSdRXkf+hteam0dxUSQgCFEBAV6uPHNFW/w8XE4dc3aycM+AZmx/fgTXd4+ga0QAv2+v5QEhuMXpy09Lc3KB3tZ5g1YjzfBS4jo4Ye0hpOw2cwQnE+2ribb+aAr6dL7RPrFdkXmE1HhAy2qlCpCAIEQVcbKY9f5XdGzEjiMniTuWwaaENBbvTKqbNZ473wQRfaDTDRDeAw7+ZR8yyk4xxXUAdlvrLGz6Ghp2gEYdISDKrGIqGRC2/gRTO8O3N5y9wltJtuGik1Ke/WJJQBCiil3ZKQwni+LuL2K56r2V3P7ZOt5etNvRzap8rp5wxzxoNQKaDTLDRUk77AV5ANz9IX6RWV10eKM9mZ7FYgKDbWK5MB8WToaCbNg1F3bNOf/vtxX8yThy7uvEWUlAEKKKBXu70b9FMAdSsxnVKYxBrUL4Pjah5u9PqIg2owBlkuc1H2KOuflCl/FwYBUseApcvaHzDfb3hHWBY9tMMNj4JaQnwOj3wTsU9i49/+/Msm4SlB7CRZOAIEQ1eHRYK27t3ZRXr+vIXf2iScsu4O4vYpn869aavST1Yvk2MtXbwB4QwjpD34fBp6EZTup80+nlPsM6mzmFpG2w9mOzFLX5EJOGe9+y89dfKBkQkuMg7eCZ18QtgM0zKv756igJCEJUgw7hfjw3uj3uLk70jg6iZag3q/ak8sVfB5i39aijm1c1OlwLKGjUGVqOhHbXmP0LN3wHLUdAn4dOvz68u3lc9jok7zCTzUqZim1ZSeefLLbNM2QcgRk3wTfjzgwiq/4Li1+slI9XF0n6ayGqmcWi+PG+PhQXw/XT/uLFOTsI8/egcxN/AE7mFnAsPZcWoT4ObmkFdbsDmvQyNZ5v/M5+vGF7uLGMv9L9I8wS1m0/g3Iyz8H0EAD2LT89uV5pth5CxhFTFhRMjegWQ+3XZB6D9ESz38HJ5cx71HPSQxDCAXzcXfDzdOHFqzuQmVfIVe+t5NEZm/hy9QGGv7mMkVOXczgtx9HNrBiLxXz5X4iBT5qdy80GgVewORbQFLxCTF2Gc8lOASdXezCwuMDKt0+/JuOYmdcoazhJSEAQwpG6NQ1g5aTBPDS4Ob9uPswzv2zF09WJIq2ZsS7B0c2rfiGtYOyXZ26CC21v0mDkZcCx7VBcKu14UYEp9WnrQSiLGZLav9z+5V+QY68LbdsfIU4jAUEIB/N2c+ax4a1Y9sQglk0cxKJHB9CvRQgz1iVwMDUbrTVJJ3PZl1IJtQdqgzZXQEjL0481bA9JO2HuE/BBb5ja0QwH2WRbq7g17GgeG7QzZULBDEGBGS6yOS4BoSwSEISoIRr7exAR5InForilV1OOnsyl/2uL6feq+Rn17gqy8wuJT8qkuLgOrkw6l9AOJrXFlu/NvISrN3x1DWy2zk3Y5g9s1d3CYyAwytRtWP8Z/Hg3JKyz3+/E/upsfa0hAUGIGmho21B+eaAvU65qT8tQH/o0CyIjt5DJv25j6JtL+cpah6HesM1FFBdC7wdgwmKTA2n2wyZjqm1TWkhr6HkfdLvVvO4wxmyQ2/I9rPnQHLO4SA/hLFRtWgMdExOjY2NjHd0MIaqd1poBry3h4PFsACICPVn8+MBT6THqvKIC+L8wMzfwxF5w9TLFdaYNNI8hreDYVnhgrXle8n0HVsLP90HmUTPh3DjG7IC+/68Lb8eWH0xN6paXVtpHqw5KqfVa67NUQLKTHoIQtYBSijHdTAqI0Z3DOHg8mw+WxHMyt57UIXZyMfmRWl1mggGYPQ33LDNzDse2mmOewWe+L3qgyZmki01ACe9ueg0Ja8/9O4uLz9zH8OOd8M3Y0wsC1SESEISoJe7qF83Ht8TwxphOdGriz+u/x3HN+6vILyw+/5vrgvE/mqI8JXkFw3WfwshXoeP14BFQ9ntD21mvbwAdx5qg8skw+4RzSfuWQX4W/HAbfDuu7PvtnH3RH6Mmk4AgRC3h4erEsLahODtZ+Pm+PrxzQxfikzJ5a1EcK3an1P2JZhd3cHY787hS0PMeuGaa2ftQFtschE+oqQ73zy1m6Gj2PyH9kP26/Svg8yvh48Gw/VdIWGM/V3Kp65pp50+lUQtJQBCiFrJYFKM6hTG0TSgfLNnD+E/W8Nmq/Y5uVs0Vag0I3g3No6uXCSD5WbD2I/t1m78Fi7M9TUbOCfuS1tw08xgYDQmrTRbWOqZcAUEpNUIptUspFa+UmlTGeTel1Azr+TVKqUjr8SCl1GKlVKZS6t1S73FVSk1TSsUppXYqpa6tjA8kRH3y2nUdeeeGLvRrEcxrC3bx3uJ44o5lAHAiq26Oc1+UwGamLrRPQ/uxoGbQpCfs+dO8zs+Gbb+aoacxn8HQZ81x2yY2W2Do97hZzTT/SchNr6YPUD3OGxCUUk7Ae8BIoC1wg1KqbanL7gROaK2bA28Br1iP5wLPAI+XceungSStdUvrfcuR31YIUVKAlyujOoXx8rUd8XZ35rUFu7jpf2t4cc52evzfInYdzeCZX7Yyf2s9rxHg5AzjvoF+j55+vNlAOLoFMpNh9++Qn2ECQruroYV1JdHOOfByhH34yDsULn/TZFX9fFSdCgrl6SH0AOK11nu11vnAd8DoUteMBj63Pv8BGKKUUlrrLK31CkxgKO0O4CUArXWx1lqqYwtxkRr7e7DyX4P54d7epGTm8fHyfRQUaR793uRHemnezro/x3A+zQaZus8lRQ82j/uWwt4lpmZD077mmO3adf8zX/q2noRnIET2hbFfmII+f39fDY2vHuUJCI2BkklVEq3HyrxGa10IpANBZ7uhUsrf+vQFpdQGpdRMpVRouVsthDiDq7OFmMhAJvSPpnVDH0a0a8i2wydxtigOpGazNC7Z0U2secI6mypuuxea1UVN+5reBJgKcD5h9h6ArZqbZ6B5bDXSrFo6tMG8PrwJ5j9V/snm7ONmf0QN2jXtqEllZyAcWKW17gr8Bbxe1oVKqQlKqVilVGxysvwPLcT5PDmyDfMe7sd9A5sB8MSIVjTwceONhbtIOllWZ70es1jTbG/9EY7vsafatgmMtj9P3WMePa1/6yplqrwdtgaEv96D1e9B8i4zWX2+wHBgJWz+Br4eCzlplfN5Kqg8AeEQ0KTE63DrsTKvUUo5A37AuapipwLZwE/W1zOBrmVdqLWeprWO0VrHhISElKO5QgilFJ2a+PPHYwO4u180z41qR3xSJpe9s5yfNyby1sI49iZnOrqZNUPfh+0ps6P6nX4uMNL6RAHapNd29bafb9zVBIDcdFMrGszqozfbwKJnz/1706wDLym7TL6lshTmQ0H1BfHyBIR1QAulVJRSyhUYB8wqdc0swJo8hOuAP/U5cmJYz80GBloPDQG2X0C7hRDl0CzEG6UUIzs0YtaDlxDo5cojMzYz9Y/dPDJjE3mFRWTlFTq6mY4VGAWdbgDfxiZLakmNOpt5hchLzGuPQNMzsAnrAmiI/RRyrKuQlr9pAsTKqbD4JdjxW9m/N+0guHiZIav0s6Q6n/uY2RldTc5bMU1rXaiUehBYADgB07XW25RSzwOxWutZwCfAl0qpeOA4JmgAoJTaD/gCrkqpq4DhWuvtwL+s73kbSAZur9yPJoQoqWWoD78+cAnLdydzOC2HZ2dvp/uURbg6OzHrwb6E+Xs4uomOc8VbkJ955sa2mDug/bWw5GVTW8Gz1NRoWBfzuOodkxYjehDs+QMCosDFA5a+bI7fs8ykz5g2yCTou+ItEwT8I8z7M85SRjVlNxzbZoafVNXnrSpXCU2t9Vxgbqljk0s8zwXGnOW9kWc5fgDoX9Y5IUTV8HB1Yni7hmitWbPvOMez8tl2+CT3frWeF6/qQIdwv/PfpC5ydgXnwDOPW5zMJLKfySN1akLZxruB2fF8KNbkWWo+1ASETjdAv8cg/SB8PATm/Qtu/gUObwQ0/DTBTFr7R5i03iVrNZSUnQp5J80GudK/uwpITWUh6iGlFB+M7wbA79uO8o/vNnLluyt4Y0wnrrUm0RMl+FunUcv6Ur5rkf15VrIp3NP1FrNaKTAa+k+EBU+aHgbabJI7vgec3c3GuLxMOLCq7N9r2wx3Yn+1BARJXSFEPTe8XUPWPDWULhH+vDRvJ1N+287EmZtJsKbaFoCfLSCUsZpeKfuPdwO44RvwbWQ/H27NOn1gpXlsa93GVZhregg+oSY1d8I6WGNNo5GwFgrzTM8Aqq3kpwQEIQR+Hi5MvqItKZl5/G/FPn7dfJjLpi7nUFqOo5tWM9iGjDwu4q90/6bm8YC1/kLrK0A5Wc9FmPxKRfmweArMewIWTjaZWDd8AbrIXFdNexUkIAghAOgSEcDUcZ2ZMaEXC/7Zn8JizbOztpGVV8jWQ+mkZuY5uomO4x0KPe81tRcu+L0NwNnDVHYDk0PJln3V1kMA+7DRyqnm8fBG+z2qKSDIHIIQ4pTRne1JCB4e2oKX5+2k3X8WABDg6cIH47vRK/qsSQjqLqVg5Cvnv+5s7/WPMPsNXLzA3c8U6TmyGfwi7PsMivLNnEPaQUCZHEs2EhCEEI50d79oIgI92ZeSRaivO+8viee+r9az7umhODvJ4MIFCWhqAoJvmAkQPSaYoSKvYLOKyGbos6ZW9Oej7Cm4A6Lg+P5qaaYEBCFEmZwsiss62CdH3V0sPPjNRjYnptOtaQCpmXl4ujrj4erkwFbWErZ5BN8w8xjSCgZMNM+9S6RxC21vVhP5NoJj1h5C466mslthvlkeW4UkIAghyuWS5sEoBb9sPMSUOdvZeDANFyfFbX0iefry0hnxxWkCbAGhdF5QwM3bpMPQxfYMqz4lVil1HGd2TBcXAhIQhBA1gL+nKx3D/fly9QFcnBQTL23F5oQ0Pl6+j7ExTWgR6sOe5EzCAzxwc5Zew2lK9xBK8w41cwsWp9OvUxaz2a3l8KpvI7LKSAhxAQa0CAbg3gHNeGBQc16+tiPuLhY+WLqHlMw8Rry9jA+W7HFwK2sg21/+ZwsIA56A/iXqiNmu8wg4e53oKiA9BCFEud3QM4L8Is0Dg5oDEOjlyrjuEXy1+gAtQ30oKNLM33qUfw5t6eCW1jCh7WHIf0yq7bJ0Gnf6ax9bQKj63cklSQ9BCFFujfw8mDSyNe4u9iGh8b2aUliseWthHAA7j2bILufSLBZTvrO86SdsO53L2hldhSQgCCEqpHkDb2KaBpBXWEyPKPOFt2jHWZK1ifKxDRlVQ/6ikiQgCCEq7PruJtfPHX0jaRnqzddrDpJfWHzGdVrrMo+LUtz9wcWz2oeMZA5BCFFh13QNx8fdheFtQ3FxsnDn57Hc/UUsOQVF+Hm48MSlrWgR6sNnq/bz3z/jWfGvQXi6ytfPWSkFl78BDap3Oa/0EIQQFeZkUYxo3xCLRTGkTSijOoWxIj6F/MJi1u0/zp2fx3I8K5/pK/dxPCufVfHnqrArAOh8I4R1rtZfqc5R6bLGiYmJ0bGxsY5uhhDiPAqLiskuKMLX3YUNB08w7qPVNPB1I/GEyZ56U88IXry6g4NbWX8opdZrrWPOd530EIQQlc7ZyYKvuwsAXSMCePfGLiSdzMPf04WBrUJYsiuZ2vTHaH0hAUEIUeWGt2vID/f15pNbuzOiXUMOpeXQ6pn5fLPmoKObJkqQWR0hRLXoGO4PQMtQb+KOZbJqTwqv/76LUZ3D2HX0JO8v3oOnmzOTRramsb+Hg1tbP0lAEEJUKx93FyZf2ZbNCWmMfm8ld3y2jq2H0vF0dSYlM4/WDX1O7YQW1UuGjIQQDtGpiT//GNKCI+k5tA/zY+7Dl9Ay1Ju1+447umn1lvQQhBAO8+iwljw6zJ73qHtkIL9uOkxRscbJohzYsvpJeghCiBqjR1QgmXmFPD5zM68t2Ono5tQ70kMQQtQYtlxIP288BMDg1g0I8nKjSaCn9BiqgQQEIUSN0cjPg0vbhdIkwJNfNh3mho/XkF9YTKivG+/f1JWuEQEUFWup6VxFJCAIIWqUj242G2o7NvHn/cXxjO7cmOkr9/HfP+NpHuLNoh3HWPBIf6nKVgUkIAghaqRRncIY1cmkgc7MK+CDJXtYtSeV/MJiftl4iDHdmmCRYaRKJf0uIUSNd03XcIo1FBQVExHoyZTfdtD86bnc//V6TmTlO7p5dUa5AoJSaoRSapdSKl4pNamM825KqRnW82uUUpHW40FKqcVKqUyl1LtnufcspdTWinwIIUTd1izEmwEtQ7iuazjPjWqHi7OFyzuGsXD7MSbP2sbWQ+k8N3sbxyU4VMh5h4yUUk7Ae8AwIBFYp5SapbXeXuKyO4ETWuvmSqlxwCvA9UAu8AzQ3vpT+t7XAJkV/hRCiDrv8zt6nHq+4ZlhADw/240vV+9n19GTxB3LZP7Wo/xwXx9JfXGRytND6AHEa633aq3zge+A0aWuGQ18bn3+AzBEKaW01lla6xWYwHAapZQ38Cgw5aJbL4So127qFUFBkSbuWCZ394siNSufN37f5ehm1VrlCQiNgYQSrxOtx8q8RmtdCKQD56sO/QLwBiDVuIUQF8U2lNS8gTf/GtGa2/pE8vPGQ+w6mkHSyVxmbz7MpoQ0Rzez1nDIKiOlVGegmdb6Edt8wzmunQBMAIiIiKj6xgkhapUPxnel0Lo34b4Bzfh2zUFeW7CT9JwC1nWssCEAAAsCSURBVO0/AcCcf1xCuzA/B7e05itPD+EQ0KTE63DrsTKvUUo5A37AuWrk9QZilFL7gRVAS6XUkrIu1FpP01rHaK1jQkJCytFcIUR94unqfKoYT4CXK/cObMaiHUms23+Ch4e0wNXJwk8bSn9libKUJyCsA1oopaKUUq7AOGBWqWtmAbdan18H/KnPUQ5Ja/2B1jpMax0JXALEaa0HXmjjhRCitNv7RtLAx41WoT48NLg5g1qH8OumwxQWFbN8dzILtx9zdBNrrPMOGWmtC5VSDwILACdgutZ6m1LqeSBWaz0L+AT4UikVDxzHBA0ArL0AX8BVKXUVMLzUCiUhhKg0nq7OzH7oEtycLTg7Wbi6S2MWbDvG0z9v5aeNibg7O7Hu30Nxd5GdzqWp2lTXNCYmRsfGxjq6GUKIWqSgqJh/freJOVuO4OPuTEZuIdNu7sbwdg0d3bRqo5Rar7WOOe91EhCEEPXBmr2phAd6csU7y4kI8sLPw4W7+0XRPTIQN2cLStXdNBjlDQiSy0gIUS/0jDYr4Ue0b8S3aw/i6mxhWVwyAH2bB/HJrd3r/TCSBAQhRL3y2PCW9IgKYGibUGasS+BIei7TV+7jse83895NXUnNzCPQy7VO9xjORgKCEKJeCfZ24+ou4QDc1S8agABPF17/PY4m83Yybdke7h/YnMcvbeXIZjqEZDsVQtR7d/WLprG/Bx8u3YOTRfHu4ngW70xydLOqnQQEIUS95+7ixFOXtSHQy5Vv7+5FdLAXby+KA6CouPYsvKkoGTISQgjg8o6NGNG+IU4Wxc29m/Lc7O088M0GFmw9SpcIf/5zZTvaN67b6S+khyCEEFZO1gps13QJx83Zwpy/j9AzOpCE4zmM+fAv/tpzrow8tZ8EhP9v7/5jq6rPOI6/n/6ESikUuoLyW1BXyRBwVWM1JC4wWAwswUTNnBENmdvYzOYim3Mxi0um0Y05f4VtRFGDLlMj29xkgEznFKHKr64gP4aDorRWrGixhfbZH+dQ75peuGvvvac99/NKmnvu93577/Pk294n53vO+R4RkW7KSgq5edbZXDntTB69oZo/Lqmhcmgxdzy/gxMdnbSf6GT7wZaow0w7TRmJiPTgli+d07VdUVrM0rmf5xtP1PLr9XuoO9TC2vpG7r1qGueNKmXM8MEMKymKMNr0UEEQEUnBnPMrmXVuBb9atxuAseWDue2ZbXR0OpdOHsHKRRfxYWs7I4YURxxp76kgiIikwMxYcf0XeW1fM63tHXxhTBnf+/0WBhcWsLb+MHOWvUzDkWP8/Qez+NzQQVGH2ysqCCIiKcrLMy6dPLLr+ZM3XUz7iU7mLHuZd5o/4XiH8/SmAyy5YkqEUfaeDiqLiPRBUUEeKxdV86cll1EzeSSr3vjPgL12QQVBRKSPxpaXcO6oUq67ZDyHWj7lvjW7aDraxvaDLRw8MnBuG68pIxGRNJldVck11eN4aMNeHtqwF4DSQQWs//4sNuxqZHbVKMpKCiOOMjkVBBGRNDEz7lowlarRpRzvcIYMKuC2Z7ax4MFXafjwGGvPP8wjX5vZb1dSVUEQEUmjYOmLCV3PX9/XzLNvNjCp4gxerDvMqjcOcO1F46IL8BRUEEREMujHX6li6pllXFM9jptWbuJHz21n0/4PuO6S8cwYNzzq8P6HDiqLiGRQ+RlFLKqZyOCifB69oZrFl0/ixbr3WPjwP9n13tGufi3HjvNO8ycRRqp7KouIZF3zx23MuncDF4wdxtypoxlclMd9a96mpfU4G2+/gpKi9E7e6J7KIiL91IghxXxz1mTu/utOXtn9PgAlRfm0tnewpu4wC6afFUlcKggiIhG4sWYiFaXFTBtTRmt7B2cNH8z8B17lubcaIisIOoYgIhKBooI8Fs4cw5TKUqaNHcbIIcUsmH4mr+xu4jur3mL11kO0HDvOSzsbufmJ2qxc/aw9BBGRfmLxZWfTdLSNtfWNrN56iPw8o6PTOadyCE1H2xhVltlF81QQRET6ibKSQu5ZOI2OTmfLgSOsrW9k6KBCFtVMoLggP+Ofr4IgItLP5OcZM8eXM3N8eVY/V8cQREQEUEEQEZFQSgXBzL5sZrvMbI+ZLe3h9WIzezp8faOZTQjbR5jZS2b2sZk9kNC/xMz+bGY7zazOzH6eroRERKR3TlsQzCwfeBCYC1QB15hZVbduNwJH3H0y8Evg7rD9U+AO4NYe3vpedz8PmA5camZze5eCiIikQyp7CNXAHnff5+7twFPA/G595gOPhdt/AK4wM3P3T9z9HwSFoYu7t7r7S+F2O/AmMKYPeYiISB+lUhDOAg4kPD8YtvXYx91PAC3AiFQCMLNhwJXAulT6i4hIZkR6UNnMCoBVwP3uvi9Jn8VmttnMNjc1NWU3QBGRHJJKQWgAxiY8HxO29dgn/JIvA5pTeO/lwG53X5asg7svd/cL3f3CioqKFN5SRER6I5UL0zYBU8xsIsEX/9XAtd36rAauB14DFgLr/TTrapvZXQSF46ZUg62trX3fzN5JtX83I4H3e/m7A5Vyzg3KOXf0Nu/xqXRK6X4IZjYPWAbkAyvc/Wdm9lNgs7uvNrNBwOMEZwx9AFx9cgrIzPYDQ4Ei4ENgNvARwTGHnUBb+DEPuPtvU07v/2Rmm1NZDzxOlHNuUM65I9N5p7R0hbu/ALzQre0nCdufAlcl+d0JSd62f95lWkQkR+lKZRERAXKrICyPOoAIKOfcoJxzR0bzHlD3VBYRkczJpT0EERE5hdgXhNMtzBcnZrbfzLab2RYz2xy2lZvZ38xsd/g4POo4+8LMVphZo5ntSGjrMUcL3B+O/TYzmxFd5L2XJOc7zawhHOst4ZmAJ1/7YZjzLjObE03UfWNmY8OFMf8VLoD53bA9tmN9ipyzN9buHtsfgtNk9wKTCE573QpURR1XBvPdD4zs1nYPsDTcXgrcHXWcfczxcmAGsON0OQLzgL8QnNF2MbAx6vjTmPOdwK099K0K/86LgYnh339+1Dn0IufRwIxwuxR4O8wttmN9ipyzNtZx30NIZWG+uEtcePAxYEGEsfSZu79McK1LomQ5zgdWeuB1YJiZjc5OpOmTJOdk5gNPuXubu/8b2EPwfzCguPu77v5muH0UqCdYMy22Y32KnJNJ+1jHvSCksjBfnDiwxsxqzWxx2Fbp7u+G2+8BldGEllHJcoz7+H87nB5ZkTAVGLucw/urTAc2kiNj3S1nyNJYx70g5Joad59BcO+Kb5nZ5YkverCfGevTynIhx9DDwNnABcC7wH3RhpMZZjYEeAa4xd0/SnwtrmPdQ85ZG+u4F4RUFuaLDXdvCB8bgecIdh8Pn9x1Dh8bo4swY5LlGNvxd/fD7t7h7p3Ab/hsqiA2OZtZIcEX45Pu/mzYHOux7innbI513AtC18J8ZlZEsDDf6ohjyggzO8PMSk9uE6wZtYPPFh4kfHw+mggzKlmOq4Gvh2egXAy0JEw3DGjd5se/SjDWEOR8tQW3tZ0ITAHeyHZ8fWVmBvwOqHf3XyS8FNuxTpZzVsc66iPrWThyP4/gaP1e4Pao48lgnpMIzjjYCtSdzJXgRkXrgN3AWqA86lj7mOcqgt3m4wRzpjcmy5HgjJMHw7HfDlwYdfxpzPnxMKdt4RfD6IT+t4c57wLmRh1/L3OuIZgO2gZsCX/mxXmsT5Fz1sZaVyqLiAgQ/ykjERFJkQqCiIgAKggiIhJSQRAREUAFQUREQioIIiICqCCIiEhIBUFERAD4LzAnyWwPkfanAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb8bf764668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch_train_loss, label='train')\n",
    "plt.plot(epoch_test_loss, label='test')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85546588407923696"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets, train_preds, train_loss = loop(train_loader)\n",
    "accuracy_score(train_targets, train_preds.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38782289854226248"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(train_targets, train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75103734439834025"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_targets, test_preds, test_loss = loop(test_loader)\n",
    "accuracy_score(test_targets, test_preds.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47493500228685276"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(test_targets, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "icebergs_test = load_test_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band_1</th>\n",
       "      <th>band_2</th>\n",
       "      <th>inc_angle</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5941774d</th>\n",
       "      <td>[-15.863251, -15.201077, -17.887735, -19.17248...</td>\n",
       "      <td>[-21.629612, -21.142353, -23.908337, -28.34524...</td>\n",
       "      <td>34.966400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4023181e</th>\n",
       "      <td>[-26.0589694977, -26.0589694977, -26.058969497...</td>\n",
       "      <td>[-25.7542076111, -25.7542076111, -25.754207611...</td>\n",
       "      <td>32.615072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b20200e4</th>\n",
       "      <td>[-14.1410999298, -15.0642414093, -17.375520706...</td>\n",
       "      <td>[-14.745639801, -14.5904102325, -14.3626976013...</td>\n",
       "      <td>37.505433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e7f018bb</th>\n",
       "      <td>[-12.167478, -13.706167, -16.54837, -13.572674...</td>\n",
       "      <td>[-24.32222, -26.375538, -24.096739, -23.8769, ...</td>\n",
       "      <td>34.473900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4371c8c3</th>\n",
       "      <td>[-23.3745937347, -26.0271816254, -28.121963501...</td>\n",
       "      <td>[-25.7223434448, -27.0115776062, -23.149162292...</td>\n",
       "      <td>43.918874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     band_1  \\\n",
       "id                                                            \n",
       "5941774d  [-15.863251, -15.201077, -17.887735, -19.17248...   \n",
       "4023181e  [-26.0589694977, -26.0589694977, -26.058969497...   \n",
       "b20200e4  [-14.1410999298, -15.0642414093, -17.375520706...   \n",
       "e7f018bb  [-12.167478, -13.706167, -16.54837, -13.572674...   \n",
       "4371c8c3  [-23.3745937347, -26.0271816254, -28.121963501...   \n",
       "\n",
       "                                                     band_2  inc_angle  \n",
       "id                                                                      \n",
       "5941774d  [-21.629612, -21.142353, -23.908337, -28.34524...  34.966400  \n",
       "4023181e  [-25.7542076111, -25.7542076111, -25.754207611...  32.615072  \n",
       "b20200e4  [-14.745639801, -14.5904102325, -14.3626976013...  37.505433  \n",
       "e7f018bb  [-24.32222, -26.375538, -24.096739, -23.8769, ...  34.473900  \n",
       "4371c8c3  [-25.7223434448, -27.0115776062, -23.149162292...  43.918874  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icebergs_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_testset(icebergs_test):\n",
    "    scaler_1 = StandardScaler()\n",
    "    scaler_2 = StandardScaler()\n",
    "    \n",
    "    for _, i in icebergs_test.iterrows():\n",
    "        scaler_1.partial_fit(i.band_1.reshape(1, -1))\n",
    "        scaler_2.partial_fit(i.band_2.reshape(1, -1))\n",
    "    \n",
    "    testset_x = torch.from_numpy(\n",
    "        np.stack(\n",
    "            [\n",
    "                scaler_1.transform(np.stack(icebergs_test.band_1)),\n",
    "                scaler_2.transform(np.stack(icebergs_test.band_2)),\n",
    "            ],\n",
    "            axis=1\n",
    "        ).reshape(-1, 2, 75, 75)\n",
    "    ).float()\n",
    "\n",
    "    testset_y = torch.from_numpy(np.zeros((len(testset_x), 1))).float()\n",
    "\n",
    "    testset_loader = data_utils.DataLoader(data_utils.TensorDataset(testset_x, testset_y), batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    targets, preds, loss = loop(testset_loader, training=False)\n",
    "    \n",
    "    icebergs_test['is_iceberg'] = preds\n",
    "    \n",
    "    icebergs_test[['is_iceberg']].to_csv('data/submission.csv')\n",
    "    \n",
    "    return targets, preds, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, p ,l = predict_testset(icebergs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band_1</th>\n",
       "      <th>band_2</th>\n",
       "      <th>inc_angle</th>\n",
       "      <th>is_iceberg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5941774d</th>\n",
       "      <td>[-15.863251, -15.201077, -17.887735, -19.17248...</td>\n",
       "      <td>[-21.629612, -21.142353, -23.908337, -28.34524...</td>\n",
       "      <td>34.966400</td>\n",
       "      <td>0.384710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4023181e</th>\n",
       "      <td>[-26.0589694977, -26.0589694977, -26.058969497...</td>\n",
       "      <td>[-25.7542076111, -25.7542076111, -25.754207611...</td>\n",
       "      <td>32.615072</td>\n",
       "      <td>0.408176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b20200e4</th>\n",
       "      <td>[-14.1410999298, -15.0642414093, -17.375520706...</td>\n",
       "      <td>[-14.745639801, -14.5904102325, -14.3626976013...</td>\n",
       "      <td>37.505433</td>\n",
       "      <td>0.085300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e7f018bb</th>\n",
       "      <td>[-12.167478, -13.706167, -16.54837, -13.572674...</td>\n",
       "      <td>[-24.32222, -26.375538, -24.096739, -23.8769, ...</td>\n",
       "      <td>34.473900</td>\n",
       "      <td>0.550635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4371c8c3</th>\n",
       "      <td>[-23.3745937347, -26.0271816254, -28.121963501...</td>\n",
       "      <td>[-25.7223434448, -27.0115776062, -23.149162292...</td>\n",
       "      <td>43.918874</td>\n",
       "      <td>0.502737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     band_1  \\\n",
       "id                                                            \n",
       "5941774d  [-15.863251, -15.201077, -17.887735, -19.17248...   \n",
       "4023181e  [-26.0589694977, -26.0589694977, -26.058969497...   \n",
       "b20200e4  [-14.1410999298, -15.0642414093, -17.375520706...   \n",
       "e7f018bb  [-12.167478, -13.706167, -16.54837, -13.572674...   \n",
       "4371c8c3  [-23.3745937347, -26.0271816254, -28.121963501...   \n",
       "\n",
       "                                                     band_2  inc_angle  \\\n",
       "id                                                                       \n",
       "5941774d  [-21.629612, -21.142353, -23.908337, -28.34524...  34.966400   \n",
       "4023181e  [-25.7542076111, -25.7542076111, -25.754207611...  32.615072   \n",
       "b20200e4  [-14.745639801, -14.5904102325, -14.3626976013...  37.505433   \n",
       "e7f018bb  [-24.32222, -26.375538, -24.096739, -23.8769, ...  34.473900   \n",
       "4371c8c3  [-25.7223434448, -27.0115776062, -23.149162292...  43.918874   \n",
       "\n",
       "          is_iceberg  \n",
       "id                    \n",
       "5941774d    0.384710  \n",
       "4023181e    0.408176  \n",
       "b20200e4    0.085300  \n",
       "e7f018bb    0.550635  \n",
       "4371c8c3    0.502737  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icebergs_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
