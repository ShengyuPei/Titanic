{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% run 0-utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "import torchvision.datasets as dset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorboardX import SummaryWriter\n",
    "import networkx as nx\n",
    "from scipy import spatial\n",
    "import scipy.sparse.csgraph\n",
    "from timeit import default_timer as timer\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gcnn.graph import *\n",
    "from gcnn.coarsening import graclus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_size = 28\n",
    "gr = grid_coordinates(gr_size)\n",
    "gr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(z, k=4, metric='euclidean'):\n",
    "    d = spatial.distance.pdist(z, metric)\n",
    "    w = spatial.distance.squareform(d)\n",
    "    \n",
    "    knc = KNeighborsClassifier(n_neighbors=k, metric=metric)\n",
    "    knc.fit(z, np.zeros_like(z)) \n",
    "    \n",
    "    closest = knc.kneighbors(z, return_distance=False)\n",
    "\n",
    "    w = np.zeros_like(w)\n",
    "    for i in range(len(w)):\n",
    "        w[i, closest[i]] = 1\n",
    "        w[i, i] = 0\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = knn(gr, k=8) > 0\n",
    "plt.spy(mask[:40, :40]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs, perm = graclus.coarsen(sp.sparse.csr.csr_matrix(mask), levels=3, self_connections=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laps = [sp.sparse.csgraph.laplacian(g, normed=True) for g in graphs[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = laps[0].shape[0]\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourier(laplacian):\n",
    "    eigenvalues, eigenvectors = sp.linalg.eigh(laplacian)\n",
    "    return eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l0 = torch.from_numpy(laps[0].todense()).float()\n",
    "l0.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = torch.from_numpy(laps[1].todense()).float()\n",
    "l1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = torch.from_numpy(laps[2].todense()).float()\n",
    "l2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = torch.from_numpy(fourier(laps[0].todense())).float()\n",
    "f0.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = torch.from_numpy(fourier(laps[1].todense())).float()\n",
    "f1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = torch.from_numpy(fourier(laps[2].todense())).float()\n",
    "f2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = './data'\n",
    "train = dset.MNIST(data_folder, train=True, download=True)\n",
    "test = dset.MNIST(data_folder, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = zip(*train)\n",
    "test_x, test_y = zip(*test)\n",
    "\n",
    "train_x = np.stack([np.r_[np.reshape(i, -1) / 255.0, np.zeros(n - gr_size * gr_size)] for i in train_x])[:, perm]\n",
    "test_x = np.stack([np.r_[np.reshape(i, -1) / 255.0, np.zeros(n - gr_size * gr_size)] for i in test_x])[:, perm]\n",
    "\n",
    "train_x = torch.from_numpy(train_x).float()\n",
    "test_x = torch.from_numpy(test_x).float()\n",
    "train_y = torch.from_numpy(np.array(train_y)).long()\n",
    "test_y = torch.from_numpy(np.array(test_y)).long()\n",
    "\n",
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "train_loader = data_utils.DataLoader(data_utils.TensorDataset(train_x, train_y), batch_size=batch_size, shuffle=True)\n",
    "test_loader = data_utils.DataLoader(data_utils.TensorDataset(test_x, test_y), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gcnn.nets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = PaperGCFC(l0.cuda() if cuda else l0, l2.cuda() if cuda else l2)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.Adam(net.parameters(), lr=0.0003)#, weight_decay=0.005)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.02, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "if cuda:\n",
    "    net.cuda()\n",
    "    criterion.cuda()\n",
    "\n",
    "#writer.add_graph(net, net(Variable(train_x[0].unsqueeze(0)).cuda()))\n",
    "    \n",
    "epoch_train_loss = []\n",
    "epoch_test_loss = []\n",
    "\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop(net, loader, training=False):\n",
    "    \n",
    "    running_loss = 0\n",
    "    targets = []\n",
    "    predictions = []\n",
    "    start = timer()\n",
    "    \n",
    "    for batch_id, (x, y) in enumerate(loader):\n",
    "        x = Variable(x)\n",
    "        y = Variable(y)\n",
    "        \n",
    "        if cuda:\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net(x)\n",
    "        loss = criterion(outputs, y)\n",
    "        \n",
    "        ps = torch.cat([p.view(-1) for p in net.fc.parameters()])\n",
    "        #loss += 0.0005 * F.l1_loss(ps, target=torch.zeros_like(ps), size_average=False)\n",
    "        loss += 5e-4 * F.mse_loss(ps, target=torch.zeros_like(ps), size_average=False)\n",
    "\n",
    "\n",
    "        if training:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        running_loss += loss.data.cpu()[0]\n",
    "        targets.extend(y.data.cpu().numpy())\n",
    "        predictions.extend(outputs.data.cpu().numpy())\n",
    "        \n",
    "        if (batch_id + 1) % 10 == 0 and training:\n",
    "            print(running_loss / (batch_id * batch_size), end='\\r')\n",
    "        \n",
    "    if training:\n",
    "        scheduler.step()\n",
    "        \n",
    "    return np.array(targets), np.array(predictions), running_loss, (timer() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(5):\n",
    "\n",
    "    train_targets, train_preds, train_loss, train_duration = loop(net, train_loader, training=True)\n",
    "    writer.add_scalar('data/train_loss', train_loss, e)\n",
    "    train_acc = accuracy_score(train_targets, train_preds.argmax(axis=1))\n",
    "    writer.add_scalar('data/train_accuracy', train_acc, e)\n",
    "      \n",
    "    test_targets, test_preds, test_loss, test_duration = loop(net, test_loader, training=False)\n",
    "    writer.add_scalar('data/test_loss', test_loss, e)\n",
    "    test_acc = accuracy_score(test_targets, test_preds.argmax(axis=1))\n",
    "    writer.add_scalar('data/test_accuracy', test_acc, e)\n",
    "\n",
    "    train_loss /= len(train)\n",
    "    test_loss /= len(test)\n",
    "    \n",
    "    epoch_train_loss.append(train_loss)\n",
    "    epoch_test_loss.append(test_loss)\n",
    "    \n",
    "    print(e, 'Training {:.4f} {:.2f}% Testing {:.4f} {:.2f}% Duration {:.2f}s {:.2f}s'.format(\n",
    "        train_loss, train_acc * 100, test_loss, test_acc * 100, train_duration, test_duration\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch_train_loss, label='train')\n",
    "plt.plot(epoch_test_loss, label='test')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets, train_preds, train_loss, train_duration = loop(net, train_loader)\n",
    "accuracy_score(train_targets, train_preds.argmax(axis=1)), train_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(train_preds.argmax(axis=1) == train_targets) / 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_targets, test_preds, test_loss, test_duration = loop(net, test_loader)\n",
    "accuracy_score(test_targets, test_preds.argmax(axis=1)), test_duration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
