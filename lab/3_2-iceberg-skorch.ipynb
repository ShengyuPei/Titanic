{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "% run 1-datasource.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from skorch.net import NeuralNetClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_1 = StandardScaler()\n",
    "scaler_2 = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, i in icebergs.iterrows():\n",
    "    scaler_1.partial_fit(i.band_1.reshape(1, -1))\n",
    "    scaler_2.partial_fit(i.band_2.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y = icebergs.is_iceberg.values.astype(np.float32)\n",
    "x = (\n",
    "    np.stack(\n",
    "        [\n",
    "            scaler_1.transform(np.stack(icebergs.band_1)),\n",
    "            scaler_2.transform(np.stack(icebergs.band_2)),\n",
    "        ],\n",
    "        axis=1\n",
    "    ).reshape(-1, 2, 75, 75)\n",
    ").astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float32'), dtype('float32'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype, y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x), type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1604,), (1604, 2, 75, 75))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "insize1 = 2 \n",
    "outsize1 = 32 \n",
    "outsize2 = 32\n",
    "outsize3 = 32 \n",
    "outsize4 = 32 \n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,outsize1=32,outsize2=32):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(insize1, outsize1, kernel_size=5, stride=1, padding=2, groups=2),\n",
    "            nn.BatchNorm2d(outsize1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(4)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(outsize1, outsize2, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(outsize2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(outsize2, outsize3, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(outsize2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(outsize3, outsize4, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(outsize2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#redifining scoring for sklearn \n",
    "from skorch import NeuralNet\n",
    "from skorch.utils import to_numpy\n",
    "from sklearn.metrics import log_loss\n",
    "class NNplusplus(NeuralNet):\n",
    "    def score(self,X,target):\n",
    "        y_preds = []\n",
    "        for yp in self.forward_iter(X, training=False):\n",
    "            y_preds.append(to_numpy(yp.sigmoid()))\n",
    "       \n",
    "        y_preds = np.concatenate(y_preds, 0)\n",
    "   \n",
    "        return log_loss(target,y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NNplusplus(\n",
    "    Net,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    criterion=nn.BCEWithLogitsLoss, #regularization\n",
    "    max_epochs=250,\n",
    "    batch_size=25,\n",
    "    lr=0.000001,\n",
    "    use_cuda = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float32'), dtype('float32'))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype, y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m0.6976\u001b[0m        \u001b[32m0.7141\u001b[0m  1.9319\n",
      "      2        \u001b[36m0.6947\u001b[0m        0.7175  0.9357\n",
      "      3        \u001b[36m0.6921\u001b[0m        \u001b[32m0.7136\u001b[0m  0.8975\n",
      "      4        \u001b[36m0.6896\u001b[0m        \u001b[32m0.7100\u001b[0m  0.8703\n",
      "      5        \u001b[36m0.6872\u001b[0m        \u001b[32m0.7066\u001b[0m  0.8663\n",
      "      6        \u001b[36m0.6850\u001b[0m        \u001b[32m0.7034\u001b[0m  0.8654\n",
      "      7        \u001b[36m0.6830\u001b[0m        \u001b[32m0.7004\u001b[0m  0.8704\n",
      "      8        \u001b[36m0.6811\u001b[0m        \u001b[32m0.6975\u001b[0m  0.8659\n",
      "      9        \u001b[36m0.6792\u001b[0m        \u001b[32m0.6949\u001b[0m  0.8659\n",
      "     10        \u001b[36m0.6775\u001b[0m        \u001b[32m0.6925\u001b[0m  0.8940\n",
      "     11        \u001b[36m0.6759\u001b[0m        \u001b[32m0.6901\u001b[0m  0.8681\n",
      "     12        \u001b[36m0.6743\u001b[0m        \u001b[32m0.6880\u001b[0m  0.8694\n",
      "     13        \u001b[36m0.6729\u001b[0m        \u001b[32m0.6859\u001b[0m  0.8686\n",
      "     14        \u001b[36m0.6714\u001b[0m        \u001b[32m0.6839\u001b[0m  0.8792\n",
      "     15        \u001b[36m0.6701\u001b[0m        \u001b[32m0.6821\u001b[0m  0.8687\n",
      "     16        \u001b[36m0.6688\u001b[0m        \u001b[32m0.6802\u001b[0m  0.8696\n",
      "     17        \u001b[36m0.6675\u001b[0m        \u001b[32m0.6785\u001b[0m  0.8661\n",
      "     18        \u001b[36m0.6663\u001b[0m        \u001b[32m0.6769\u001b[0m  0.8704\n",
      "     19        \u001b[36m0.6652\u001b[0m        \u001b[32m0.6753\u001b[0m  0.8720\n",
      "     20        \u001b[36m0.6640\u001b[0m        \u001b[32m0.6739\u001b[0m  0.8665\n",
      "     21        \u001b[36m0.6629\u001b[0m        \u001b[32m0.6725\u001b[0m  0.8727\n",
      "     22        \u001b[36m0.6619\u001b[0m        \u001b[32m0.6711\u001b[0m  0.8690\n",
      "     23        \u001b[36m0.6608\u001b[0m        \u001b[32m0.6697\u001b[0m  0.8712\n",
      "     24        \u001b[36m0.6598\u001b[0m        \u001b[32m0.6684\u001b[0m  0.8839\n",
      "     25        \u001b[36m0.6588\u001b[0m        \u001b[32m0.6672\u001b[0m  0.9251\n",
      "     26        \u001b[36m0.6578\u001b[0m        \u001b[32m0.6659\u001b[0m  0.8772\n",
      "     27        \u001b[36m0.6568\u001b[0m        \u001b[32m0.6647\u001b[0m  0.8770\n",
      "     28        \u001b[36m0.6559\u001b[0m        \u001b[32m0.6636\u001b[0m  0.8689\n",
      "     29        \u001b[36m0.6549\u001b[0m        \u001b[32m0.6624\u001b[0m  0.8657\n",
      "     30        \u001b[36m0.6540\u001b[0m        \u001b[32m0.6613\u001b[0m  0.8679\n",
      "     31        \u001b[36m0.6531\u001b[0m        \u001b[32m0.6602\u001b[0m  0.8685\n",
      "     32        \u001b[36m0.6522\u001b[0m        \u001b[32m0.6591\u001b[0m  0.8761\n",
      "     33        \u001b[36m0.6514\u001b[0m        \u001b[32m0.6581\u001b[0m  0.8746\n",
      "     34        \u001b[36m0.6506\u001b[0m        \u001b[32m0.6571\u001b[0m  0.8679\n",
      "     35        \u001b[36m0.6497\u001b[0m        \u001b[32m0.6562\u001b[0m  0.8645\n",
      "     36        \u001b[36m0.6489\u001b[0m        \u001b[32m0.6553\u001b[0m  0.8683\n",
      "     37        \u001b[36m0.6482\u001b[0m        \u001b[32m0.6543\u001b[0m  0.8671\n",
      "     38        \u001b[36m0.6474\u001b[0m        \u001b[32m0.6534\u001b[0m  0.8721\n",
      "     39        \u001b[36m0.6466\u001b[0m        \u001b[32m0.6525\u001b[0m  0.8739\n",
      "     40        \u001b[36m0.6458\u001b[0m        \u001b[32m0.6517\u001b[0m  0.8710\n",
      "     41        \u001b[36m0.6450\u001b[0m        \u001b[32m0.6508\u001b[0m  0.8708\n",
      "     42        \u001b[36m0.6443\u001b[0m        \u001b[32m0.6500\u001b[0m  0.8676\n",
      "     43        \u001b[36m0.6435\u001b[0m        \u001b[32m0.6491\u001b[0m  0.8693\n",
      "     44        \u001b[36m0.6427\u001b[0m        \u001b[32m0.6483\u001b[0m  0.8712\n",
      "     45        \u001b[36m0.6420\u001b[0m        \u001b[32m0.6475\u001b[0m  0.8622\n",
      "     46        \u001b[36m0.6412\u001b[0m        \u001b[32m0.6467\u001b[0m  0.8698\n",
      "     47        \u001b[36m0.6405\u001b[0m        \u001b[32m0.6459\u001b[0m  0.8691\n",
      "     48        \u001b[36m0.6398\u001b[0m        \u001b[32m0.6452\u001b[0m  0.8693\n",
      "     49        \u001b[36m0.6390\u001b[0m        \u001b[32m0.6445\u001b[0m  0.8673\n",
      "     50        \u001b[36m0.6383\u001b[0m        \u001b[32m0.6437\u001b[0m  0.8779\n",
      "     51        \u001b[36m0.6376\u001b[0m        \u001b[32m0.6430\u001b[0m  0.8696\n",
      "     52        \u001b[36m0.6369\u001b[0m        \u001b[32m0.6423\u001b[0m  0.8849\n",
      "     53        \u001b[36m0.6363\u001b[0m        \u001b[32m0.6416\u001b[0m  0.8705\n",
      "     54        \u001b[36m0.6356\u001b[0m        \u001b[32m0.6409\u001b[0m  0.8884\n",
      "     55        \u001b[36m0.6349\u001b[0m        \u001b[32m0.6402\u001b[0m  0.8902\n",
      "     56        \u001b[36m0.6342\u001b[0m        \u001b[32m0.6395\u001b[0m  0.8788\n",
      "     57        \u001b[36m0.6335\u001b[0m        \u001b[32m0.6388\u001b[0m  0.8717\n",
      "     58        \u001b[36m0.6328\u001b[0m        \u001b[32m0.6381\u001b[0m  0.8749\n",
      "     59        \u001b[36m0.6322\u001b[0m        \u001b[32m0.6374\u001b[0m  0.8702\n",
      "     60        \u001b[36m0.6315\u001b[0m        \u001b[32m0.6368\u001b[0m  0.8697\n",
      "     61        \u001b[36m0.6308\u001b[0m        \u001b[32m0.6361\u001b[0m  0.8769\n",
      "     62        \u001b[36m0.6302\u001b[0m        \u001b[32m0.6354\u001b[0m  0.8622\n",
      "     63        \u001b[36m0.6296\u001b[0m        \u001b[32m0.6348\u001b[0m  0.8751\n",
      "     64        \u001b[36m0.6289\u001b[0m        \u001b[32m0.6341\u001b[0m  0.8740\n",
      "     65        \u001b[36m0.6283\u001b[0m        \u001b[32m0.6335\u001b[0m  0.8764\n",
      "     66        \u001b[36m0.6276\u001b[0m        \u001b[32m0.6328\u001b[0m  0.8687\n",
      "     67        \u001b[36m0.6269\u001b[0m        \u001b[32m0.6322\u001b[0m  0.8716\n",
      "     68        \u001b[36m0.6263\u001b[0m        \u001b[32m0.6316\u001b[0m  0.8677\n",
      "     69        \u001b[36m0.6256\u001b[0m        \u001b[32m0.6310\u001b[0m  0.8653\n",
      "     70        \u001b[36m0.6250\u001b[0m        \u001b[32m0.6303\u001b[0m  0.8725\n",
      "     71        \u001b[36m0.6243\u001b[0m        \u001b[32m0.6297\u001b[0m  0.8639\n",
      "     72        \u001b[36m0.6237\u001b[0m        \u001b[32m0.6292\u001b[0m  0.8743\n",
      "     73        \u001b[36m0.6230\u001b[0m        \u001b[32m0.6286\u001b[0m  0.8714\n",
      "     74        \u001b[36m0.6224\u001b[0m        \u001b[32m0.6280\u001b[0m  0.8734\n",
      "     75        \u001b[36m0.6217\u001b[0m        \u001b[32m0.6274\u001b[0m  0.8730\n",
      "     76        \u001b[36m0.6211\u001b[0m        \u001b[32m0.6268\u001b[0m  0.8733\n",
      "     77        \u001b[36m0.6204\u001b[0m        \u001b[32m0.6262\u001b[0m  0.8646\n",
      "     78        \u001b[36m0.6198\u001b[0m        \u001b[32m0.6257\u001b[0m  0.8832\n",
      "     79        \u001b[36m0.6191\u001b[0m        \u001b[32m0.6251\u001b[0m  0.8715\n",
      "     80        \u001b[36m0.6185\u001b[0m        \u001b[32m0.6245\u001b[0m  0.8789\n",
      "     81        \u001b[36m0.6178\u001b[0m        \u001b[32m0.6239\u001b[0m  0.8700\n",
      "     82        \u001b[36m0.6172\u001b[0m        \u001b[32m0.6233\u001b[0m  0.8709\n",
      "     83        \u001b[36m0.6165\u001b[0m        \u001b[32m0.6228\u001b[0m  0.8682\n",
      "     84        \u001b[36m0.6159\u001b[0m        \u001b[32m0.6222\u001b[0m  0.8702\n",
      "     85        \u001b[36m0.6152\u001b[0m        \u001b[32m0.6216\u001b[0m  0.8691\n",
      "     86        \u001b[36m0.6146\u001b[0m        \u001b[32m0.6210\u001b[0m  0.8719\n",
      "     87        \u001b[36m0.6139\u001b[0m        \u001b[32m0.6204\u001b[0m  0.8709\n",
      "     88        \u001b[36m0.6133\u001b[0m        \u001b[32m0.6198\u001b[0m  0.8666\n",
      "     89        \u001b[36m0.6126\u001b[0m        \u001b[32m0.6193\u001b[0m  0.8692\n",
      "     90        \u001b[36m0.6120\u001b[0m        \u001b[32m0.6187\u001b[0m  0.8667\n",
      "     91        \u001b[36m0.6113\u001b[0m        \u001b[32m0.6181\u001b[0m  0.8709\n",
      "     92        \u001b[36m0.6107\u001b[0m        \u001b[32m0.6176\u001b[0m  0.9341\n",
      "     93        \u001b[36m0.6100\u001b[0m        \u001b[32m0.6170\u001b[0m  0.8925\n",
      "     94        \u001b[36m0.6094\u001b[0m        \u001b[32m0.6164\u001b[0m  0.8676\n",
      "     95        \u001b[36m0.6087\u001b[0m        \u001b[32m0.6158\u001b[0m  0.8790\n",
      "     96        \u001b[36m0.6081\u001b[0m        \u001b[32m0.6153\u001b[0m  0.8682\n",
      "     97        \u001b[36m0.6074\u001b[0m        \u001b[32m0.6147\u001b[0m  0.8694\n",
      "     98        \u001b[36m0.6068\u001b[0m        \u001b[32m0.6141\u001b[0m  0.8709\n",
      "     99        \u001b[36m0.6061\u001b[0m        \u001b[32m0.6135\u001b[0m  0.8875\n",
      "    100        \u001b[36m0.6054\u001b[0m        \u001b[32m0.6130\u001b[0m  0.8968\n",
      "    101        \u001b[36m0.6048\u001b[0m        \u001b[32m0.6124\u001b[0m  0.8832\n",
      "    102        \u001b[36m0.6041\u001b[0m        \u001b[32m0.6118\u001b[0m  0.8702\n",
      "    103        \u001b[36m0.6035\u001b[0m        \u001b[32m0.6112\u001b[0m  0.8762\n",
      "    104        \u001b[36m0.6028\u001b[0m        \u001b[32m0.6107\u001b[0m  0.8708\n",
      "    105        \u001b[36m0.6021\u001b[0m        \u001b[32m0.6101\u001b[0m  0.8696\n",
      "    106        \u001b[36m0.6015\u001b[0m        \u001b[32m0.6095\u001b[0m  0.8697\n",
      "    107        \u001b[36m0.6008\u001b[0m        \u001b[32m0.6089\u001b[0m  0.8733\n",
      "    108        \u001b[36m0.6001\u001b[0m        \u001b[32m0.6083\u001b[0m  0.8854\n",
      "    109        \u001b[36m0.5995\u001b[0m        \u001b[32m0.6078\u001b[0m  0.8724\n",
      "    110        \u001b[36m0.5988\u001b[0m        \u001b[32m0.6072\u001b[0m  0.8704\n",
      "    111        \u001b[36m0.5981\u001b[0m        \u001b[32m0.6066\u001b[0m  0.8756\n",
      "    112        \u001b[36m0.5974\u001b[0m        \u001b[32m0.6060\u001b[0m  0.9046\n",
      "    113        \u001b[36m0.5967\u001b[0m        \u001b[32m0.6054\u001b[0m  0.9028\n",
      "    114        \u001b[36m0.5961\u001b[0m        \u001b[32m0.6049\u001b[0m  0.8694\n",
      "    115        \u001b[36m0.5954\u001b[0m        \u001b[32m0.6043\u001b[0m  0.8724\n",
      "    116        \u001b[36m0.5947\u001b[0m        \u001b[32m0.6037\u001b[0m  0.8780\n",
      "    117        \u001b[36m0.5940\u001b[0m        \u001b[32m0.6031\u001b[0m  0.8736\n",
      "    118        \u001b[36m0.5933\u001b[0m        \u001b[32m0.6026\u001b[0m  0.8713\n",
      "    119        \u001b[36m0.5926\u001b[0m        \u001b[32m0.6020\u001b[0m  0.8809\n",
      "    120        \u001b[36m0.5919\u001b[0m        \u001b[32m0.6014\u001b[0m  0.8681\n",
      "    121        \u001b[36m0.5913\u001b[0m        \u001b[32m0.6008\u001b[0m  0.8638\n",
      "    122        \u001b[36m0.5906\u001b[0m        \u001b[32m0.6003\u001b[0m  0.8609\n",
      "    123        \u001b[36m0.5899\u001b[0m        \u001b[32m0.5997\u001b[0m  0.8618\n",
      "    124        \u001b[36m0.5892\u001b[0m        \u001b[32m0.5991\u001b[0m  0.8660\n",
      "    125        \u001b[36m0.5885\u001b[0m        \u001b[32m0.5985\u001b[0m  0.8669\n",
      "    126        \u001b[36m0.5879\u001b[0m        \u001b[32m0.5980\u001b[0m  0.8623\n",
      "    127        \u001b[36m0.5872\u001b[0m        \u001b[32m0.5974\u001b[0m  0.8643\n",
      "    128        \u001b[36m0.5865\u001b[0m        \u001b[32m0.5968\u001b[0m  0.8706\n",
      "    129        \u001b[36m0.5858\u001b[0m        \u001b[32m0.5963\u001b[0m  0.8723\n",
      "    130        \u001b[36m0.5851\u001b[0m        \u001b[32m0.5957\u001b[0m  0.8850\n",
      "    131        \u001b[36m0.5844\u001b[0m        \u001b[32m0.5952\u001b[0m  0.8687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    132        \u001b[36m0.5837\u001b[0m        \u001b[32m0.5946\u001b[0m  0.8697\n",
      "    133        \u001b[36m0.5830\u001b[0m        \u001b[32m0.5940\u001b[0m  0.8742\n",
      "    134        \u001b[36m0.5823\u001b[0m        \u001b[32m0.5935\u001b[0m  0.8719\n",
      "    135        \u001b[36m0.5816\u001b[0m        \u001b[32m0.5929\u001b[0m  0.8733\n",
      "    136        \u001b[36m0.5809\u001b[0m        \u001b[32m0.5923\u001b[0m  0.8712\n",
      "    137        \u001b[36m0.5802\u001b[0m        \u001b[32m0.5918\u001b[0m  0.8734\n",
      "    138        \u001b[36m0.5795\u001b[0m        \u001b[32m0.5912\u001b[0m  0.8691\n",
      "    139        \u001b[36m0.5788\u001b[0m        \u001b[32m0.5906\u001b[0m  0.8705\n",
      "    140        \u001b[36m0.5781\u001b[0m        \u001b[32m0.5901\u001b[0m  0.8793\n",
      "    141        \u001b[36m0.5774\u001b[0m        \u001b[32m0.5895\u001b[0m  0.8698\n",
      "    142        \u001b[36m0.5767\u001b[0m        \u001b[32m0.5890\u001b[0m  0.8908\n",
      "    143        \u001b[36m0.5759\u001b[0m        \u001b[32m0.5884\u001b[0m  0.8694\n",
      "    144        \u001b[36m0.5752\u001b[0m        \u001b[32m0.5878\u001b[0m  0.8723\n",
      "    145        \u001b[36m0.5745\u001b[0m        \u001b[32m0.5873\u001b[0m  0.8725\n",
      "    146        \u001b[36m0.5738\u001b[0m        \u001b[32m0.5867\u001b[0m  0.8786\n",
      "    147        \u001b[36m0.5731\u001b[0m        \u001b[32m0.5862\u001b[0m  0.8816\n",
      "    148        \u001b[36m0.5723\u001b[0m        \u001b[32m0.5856\u001b[0m  0.8730\n",
      "    149        \u001b[36m0.5716\u001b[0m        \u001b[32m0.5851\u001b[0m  0.8774\n",
      "    150        \u001b[36m0.5709\u001b[0m        \u001b[32m0.5845\u001b[0m  0.8789\n",
      "    151        \u001b[36m0.5702\u001b[0m        \u001b[32m0.5840\u001b[0m  0.8731\n",
      "    152        \u001b[36m0.5694\u001b[0m        \u001b[32m0.5834\u001b[0m  0.8746\n",
      "    153        \u001b[36m0.5687\u001b[0m        \u001b[32m0.5829\u001b[0m  0.8800\n",
      "    154        \u001b[36m0.5680\u001b[0m        \u001b[32m0.5823\u001b[0m  0.8965\n",
      "    155        \u001b[36m0.5672\u001b[0m        \u001b[32m0.5818\u001b[0m  0.8974\n",
      "    156        \u001b[36m0.5665\u001b[0m        \u001b[32m0.5812\u001b[0m  0.8659\n",
      "    157        \u001b[36m0.5658\u001b[0m        \u001b[32m0.5807\u001b[0m  0.8691\n",
      "    158        \u001b[36m0.5650\u001b[0m        \u001b[32m0.5801\u001b[0m  0.8680\n",
      "    159        \u001b[36m0.5643\u001b[0m        \u001b[32m0.5796\u001b[0m  0.8854\n",
      "    160        \u001b[36m0.5636\u001b[0m        \u001b[32m0.5790\u001b[0m  0.8718\n",
      "    161        \u001b[36m0.5628\u001b[0m        \u001b[32m0.5784\u001b[0m  0.8701\n",
      "    162        \u001b[36m0.5621\u001b[0m        \u001b[32m0.5779\u001b[0m  0.8715\n",
      "    163        \u001b[36m0.5613\u001b[0m        \u001b[32m0.5773\u001b[0m  0.8708\n",
      "    164        \u001b[36m0.5606\u001b[0m        \u001b[32m0.5767\u001b[0m  0.8883\n",
      "    165        \u001b[36m0.5598\u001b[0m        \u001b[32m0.5761\u001b[0m  0.8727\n",
      "    166        \u001b[36m0.5591\u001b[0m        \u001b[32m0.5756\u001b[0m  0.8855\n",
      "    167        \u001b[36m0.5584\u001b[0m        \u001b[32m0.5750\u001b[0m  0.8797\n",
      "    168        \u001b[36m0.5576\u001b[0m        \u001b[32m0.5744\u001b[0m  0.8750\n",
      "    169        \u001b[36m0.5569\u001b[0m        \u001b[32m0.5738\u001b[0m  0.8707\n",
      "    170        \u001b[36m0.5561\u001b[0m        \u001b[32m0.5733\u001b[0m  0.8710\n",
      "    171        \u001b[36m0.5554\u001b[0m        \u001b[32m0.5727\u001b[0m  0.8699\n",
      "    172        \u001b[36m0.5546\u001b[0m        \u001b[32m0.5721\u001b[0m  0.8684\n",
      "    173        \u001b[36m0.5539\u001b[0m        \u001b[32m0.5716\u001b[0m  0.8693\n",
      "    174        \u001b[36m0.5531\u001b[0m        \u001b[32m0.5710\u001b[0m  0.8697\n",
      "    175        \u001b[36m0.5524\u001b[0m        \u001b[32m0.5704\u001b[0m  0.8732\n",
      "    176        \u001b[36m0.5516\u001b[0m        \u001b[32m0.5698\u001b[0m  0.8801\n",
      "    177        \u001b[36m0.5509\u001b[0m        \u001b[32m0.5693\u001b[0m  0.8725\n",
      "    178        \u001b[36m0.5501\u001b[0m        \u001b[32m0.5687\u001b[0m  0.8973\n",
      "    179        \u001b[36m0.5494\u001b[0m        \u001b[32m0.5681\u001b[0m  0.8907\n",
      "    180        \u001b[36m0.5487\u001b[0m        \u001b[32m0.5675\u001b[0m  0.8701\n",
      "    181        \u001b[36m0.5479\u001b[0m        \u001b[32m0.5669\u001b[0m  0.8722\n",
      "    182        \u001b[36m0.5472\u001b[0m        \u001b[32m0.5664\u001b[0m  0.8686\n",
      "    183        \u001b[36m0.5464\u001b[0m        \u001b[32m0.5658\u001b[0m  0.8693\n",
      "    184        \u001b[36m0.5457\u001b[0m        \u001b[32m0.5652\u001b[0m  0.8721\n",
      "    185        \u001b[36m0.5449\u001b[0m        \u001b[32m0.5647\u001b[0m  0.8769\n",
      "    186        \u001b[36m0.5442\u001b[0m        \u001b[32m0.5641\u001b[0m  0.8719\n",
      "    187        \u001b[36m0.5434\u001b[0m        \u001b[32m0.5635\u001b[0m  0.8994\n",
      "    188        \u001b[36m0.5427\u001b[0m        \u001b[32m0.5630\u001b[0m  0.8688\n",
      "    189        \u001b[36m0.5420\u001b[0m        \u001b[32m0.5624\u001b[0m  0.8710\n",
      "    190        \u001b[36m0.5412\u001b[0m        \u001b[32m0.5618\u001b[0m  0.8815\n",
      "    191        \u001b[36m0.5405\u001b[0m        \u001b[32m0.5613\u001b[0m  0.8723\n",
      "    192        \u001b[36m0.5397\u001b[0m        \u001b[32m0.5607\u001b[0m  0.8928\n",
      "    193        \u001b[36m0.5390\u001b[0m        \u001b[32m0.5601\u001b[0m  0.8772\n",
      "    194        \u001b[36m0.5382\u001b[0m        \u001b[32m0.5596\u001b[0m  0.8794\n",
      "    195        \u001b[36m0.5375\u001b[0m        \u001b[32m0.5590\u001b[0m  0.8835\n",
      "    196        \u001b[36m0.5368\u001b[0m        \u001b[32m0.5584\u001b[0m  0.8744\n",
      "    197        \u001b[36m0.5360\u001b[0m        \u001b[32m0.5579\u001b[0m  0.8804\n",
      "    198        \u001b[36m0.5353\u001b[0m        \u001b[32m0.5573\u001b[0m  0.8737\n",
      "    199        \u001b[36m0.5345\u001b[0m        \u001b[32m0.5567\u001b[0m  0.8727\n"
     ]
    }
   ],
   "source": [
    "model.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output4\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "params = {\n",
    "    'lr': [0.000001, 0.000002,0.000004,0.000008],\n",
    "    'max_epochs': [50,100,150, 200,250],\n",
    "}\n",
    "gs = GridSearchCV(model, params, refit=False, cv=3,n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
